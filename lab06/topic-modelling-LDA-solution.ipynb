{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 06 - Topic Modelling\n",
    "In this lab we will look into building topic models, but will also examine dimensionality reduction and other relevant subjects.\n",
    "\n",
    "### Latent Dirichlet Allocation (LDiA)\n",
    "\n",
    "Based on: [Evaluate Topic Models: Latent Dirichlet Allocation (LDA)](https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** **\n",
    "\n",
    "For this lab, we’ll use the dataset of papers published in NeurIPS (NIPS) conference. The CSV data file contains information on the different NeurIPS papers that were published from 1987 until 2016. These papers discuss a wide variety of topics in machine learning, from neural networks to optimization methods, and many more.\n",
    "\n",
    "** **\n",
    "#### Step 1: Loading Data\n",
    "** **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-01 12:34:24--  https://www.cse.iitb.ac.in/~diptesh/data.tar.gz\n",
      "Resolving www.cse.iitb.ac.in (www.cse.iitb.ac.in)... 103.21.127.134\n",
      "Connecting to www.cse.iitb.ac.in (www.cse.iitb.ac.in)|103.21.127.134|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 73485589 (70M) [application/x-gzip]\n",
      "Saving to: 'data.tar.gz'\n",
      "\n",
      "data.tar.gz         100%[===================>]  70.08M  12.3MB/s    in 7.4s    \n",
      "\n",
      "2022-03-01 12:34:32 (9.49 MB/s) - 'data.tar.gz' saved [73485589/73485589]\n",
      "\n",
      "data/\n",
      "data/papers.csv\n",
      "data/.DS_Store\n",
      "data/articles+4.txt\n",
      "data/authors.csv\n",
      "data/paper_authors.csv\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.cse.iitb.ac.in/~diptesh/data.tar.gz && tar -xvzf data.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (4.1.2)\n",
      "Requirement already satisfied: spacy in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (3.2.3)\n",
      "Requirement already satisfied: pyldavis in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (3.3.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from gensim) (1.22.2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from gensim) (1.8.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy) (8.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy) (1.0.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy) (2.27.1)\n",
      "Requirement already satisfied: setuptools in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy) (59.4.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: jinja2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy) (3.0.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy) (2.4.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy) (0.6.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy) (4.62.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy) (0.7.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: scikit-learn in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pyldavis) (1.0.2)\n",
      "Requirement already satisfied: funcy in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pyldavis) (1.17)\n",
      "Requirement already satisfied: numexpr in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pyldavis) (2.8.1)\n",
      "Requirement already satisfied: joblib in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pyldavis) (1.1.0)\n",
      "Requirement already satisfied: sklearn in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pyldavis) (0.0)\n",
      "Requirement already satisfied: future in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pyldavis) (0.18.2)\n",
      "Requirement already satisfied: pandas>=1.2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pyldavis) (1.4.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from packaging>=20.0->spacy) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas>=1.2.0->pyldavis) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas>=1.2.0->pyldavis) (2021.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (4.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=1.2.0->pyldavis) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from jinja2->spacy) (2.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from scikit-learn->pyldavis) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim spacy pyldavis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>event_type</th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>Self-Organization of Associative Database and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-self-organization-of-associative-database-an...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1987</td>\n",
       "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-a-mean-field-theory-of-layer-iv-of-visual-c...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>1988</td>\n",
       "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100-storing-covariance-by-the-associative-long...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>1994</td>\n",
       "      <td>Bayesian Query Construction for Neural Network...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000-bayesian-query-construction-for-neural-ne...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>1994</td>\n",
       "      <td>Neural Network Ensembles, Cross Validation, an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001-neural-network-ensembles-cross-validation...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  year                                              title event_type  \\\n",
       "0     1  1987  Self-Organization of Associative Database and ...        NaN   \n",
       "1    10  1987  A Mean Field Theory of Layer IV of Visual Cort...        NaN   \n",
       "2   100  1988  Storing Covariance by the Associative Long-Ter...        NaN   \n",
       "3  1000  1994  Bayesian Query Construction for Neural Network...        NaN   \n",
       "4  1001  1994  Neural Network Ensembles, Cross Validation, an...        NaN   \n",
       "\n",
       "                                            pdf_name          abstract  \\\n",
       "0  1-self-organization-of-associative-database-an...  Abstract Missing   \n",
       "1  10-a-mean-field-theory-of-layer-iv-of-visual-c...  Abstract Missing   \n",
       "2  100-storing-covariance-by-the-associative-long...  Abstract Missing   \n",
       "3  1000-bayesian-query-construction-for-neural-ne...  Abstract Missing   \n",
       "4  1001-neural-network-ensembles-cross-validation...  Abstract Missing   \n",
       "\n",
       "                                          paper_text  \n",
       "0  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...  \n",
       "1  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...  \n",
       "2  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...  \n",
       "3  Bayesian Query Construction for Neural\\nNetwor...  \n",
       "4  Neural Network Ensembles, Cross\\nValidation, a...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing modules\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#os.chdir('..')\n",
    "\n",
    "# Read data into papers\n",
    "papers = pd.read_csv('data/papers.csv')\n",
    "\n",
    "# Print head\n",
    "papers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** **\n",
    "#### Step 2: Data Cleaning\n",
    "** **\n",
    "\n",
    "Since the goal of this analysis is to perform topic modeling, we will solely focus on the text data from each paper, and drop other metadata columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4858</th>\n",
       "      <td>Covariance shrinkage for autocorrelated data\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6386</th>\n",
       "      <td>Clustering with a Domain-Specific\\nDistance Me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>Individualized ROI Optimization via\\nMaximizat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1605</th>\n",
       "      <td>Ambiguous model learning made unambiguous\\nwit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5673</th>\n",
       "      <td>Learning in Games: Robustness of Fast Converge...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             paper_text\n",
       "4858  Covariance shrinkage for autocorrelated data\\n...\n",
       "6386  Clustering with a Domain-Specific\\nDistance Me...\n",
       "3331  Individualized ROI Optimization via\\nMaximizat...\n",
       "1605  Ambiguous model learning made unambiguous\\nwit...\n",
       "5673  Learning in Games: Robustness of Fast Converge..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the columns\n",
    "papers = papers.drop(columns=['id', 'title', 'abstract', \n",
    "                              'event_type', 'pdf_name', 'year'], axis=1)\n",
    "\n",
    "# sample only 100 papers\n",
    "papers = papers.sample(100)\n",
    "\n",
    "# Print out the first rows of papers\n",
    "papers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove punctuation/lower casing\n",
    "\n",
    "Next, let’s perform a simple preprocessing on the content of paper_text column to make them more amenable for analysis, and reliable results. To do that, we’ll use a regular expression to remove any punctuation, and then lowercase the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: DeprecationWarning: invalid escape sequence \\.\n",
      "<>:5: DeprecationWarning: invalid escape sequence \\.\n",
      "/tmp/ipykernel_271/734592226.py:5: DeprecationWarning: invalid escape sequence \\.\n",
      "  papers['paper_text_processed'] = papers['paper_text'].map(lambda x: re.sub('[,\\.!?]', '', x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4858    covariance shrinkage for autocorrelated data\\n...\n",
       "6386    clustering with a domain-specific\\ndistance me...\n",
       "3331    individualized roi optimization via\\nmaximizat...\n",
       "1605    ambiguous model learning made unambiguous\\nwit...\n",
       "5673    learning in games: robustness of fast converge...\n",
       "Name: paper_text_processed, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the regular expression library\n",
    "import re\n",
    "\n",
    "# Remove punctuation\n",
    "papers['paper_text_processed'] = papers['paper_text'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
    "\n",
    "# Convert the titles to lowercase\n",
    "papers['paper_text_processed'] = papers['paper_text_processed'].map(lambda x: x.lower())\n",
    "\n",
    "# Print out the first rows of papers\n",
    "papers['paper_text_processed'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenize words and further clean-up text\n",
    "\n",
    "Let’s tokenize each sentence into a list of words, removing punctuations and unnecessary characters altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/gensim/matutils.py:22: DeprecationWarning: Please use `triu` from the `scipy.linalg` namespace, the `scipy.linalg.special_matrices` namespace is deprecated.\n",
      "  from scipy.linalg.special_matrices import triu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['covariance', 'shrinkage', 'for', 'autocorrelated', 'data', 'daniel', 'bartz', 'department', 'of', 'computer', 'science', 'tu', 'berlin', 'berlin', 'germany', 'danielbartz', 'tu', 'berlinde', 'klaus', 'robert', 'muller', 'tu', 'berlin', 'berlin', 'germany', 'korea', 'university', 'korea', 'seoul', 'klaus']\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data = papers.paper_text_processed.values.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:1][0][:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** **\n",
    "#### Step 3: Phrase Modeling: Bigram and Trigram Models\n",
    "** **\n",
    "\n",
    "Bigrams are two words frequently occurring together in the document. Trigrams are 3 words frequently occurring. Some examples in our example are: 'back_bumper', 'oil_leakage', 'maryland_college_park' etc.\n",
    "\n",
    "Gensim's Phrases model can build and implement the bigrams, trigrams, quadgrams and more. The two important arguments to Phrases are min_count and threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.07 s, sys: 10.8 ms, total: 2.08 s\n",
      "Wall time: 2.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Stopwords, Make Bigrams and Lemmatize\n",
    "\n",
    "The phrase models are ready. Let’s define the functions to remove the stopwords, make trigrams and lemmatization and call them sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/studio-lab-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# NLTK Stop words\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call the functions in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.9 MB 3.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from en-core-web-sm==3.2.0) (3.2.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.13)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.7.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: jinja2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.9.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.9)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.6)\n",
      "Requirement already satisfied: setuptools in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (59.4.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.22.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.62.3)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (21.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.27.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['shrinkage', 'autocorrelated', 'datum', 'abstract', 'accurate', 'estimation', 'covariance', 'matrice', 'essential', 'many', 'signal_processe', 'machine', 'learning', 'algorithm', 'setting', 'sample', 'covariance', 'know', 'perform', 'poorly', 'hence', 'regularization', 'strategy', 'analytic_shrinkage', 'ledoit', 'wolf', 'apply', 'standard', 'setting', 'iid']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1][0][:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** **\n",
    "#### Step 4: Data transformation: Corpus and Dictionary\n",
    "** **\n",
    "\n",
    "The two main inputs to the LDA topic model are the dictionary(id2word) and the corpus. Let’s create them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 3), (3, 1), (4, 2), (5, 6), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 2), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 6), (19, 2), (20, 1), (21, 3), (22, 3), (23, 5), (24, 10), (25, 7), (26, 2), (27, 1), (28, 4), (29, 3)]\n"
     ]
    }
   ],
   "source": [
    "import gensim.corpora as corpora\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1][0][:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** **\n",
    "#### Step 5: Base Model \n",
    "** **\n",
    "\n",
    "We have everything required to train the base LDA model. In addition to the corpus and dictionary, you need to provide the number of topics as well. Apart from that, alpha and eta are hyperparameters that affect sparsity of the topics. According to the Gensim docs, both defaults to 1.0/num_topics prior (we'll use default for the base model).\n",
    "\n",
    "chunksize controls how many documents are processed at a time in the training algorithm. Increasing chunksize will speed up training, at least as long as the chunk of documents easily fit into memory.\n",
    "\n",
    "passes controls how often we train the model on the entire corpus (set to 10). Another word for passes might be \"epochs\". iterations is somewhat technical, but essentially it controls how often we repeat a particular loop over each document. It is important to set the number of \"passes\" and \"iterations\" high enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.42 s, sys: 141 ms, total: 4.56 s\n",
      "Wall time: 4.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=10, \n",
    "                                       random_state=100,\n",
    "                                       chunksize=100,\n",
    "                                       passes=10,\n",
    "                                       per_word_topics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** **\n",
    "The above LDA model is built with 10 different topics where each topic is a combination of keywords and each keyword contributes a certain weightage to the topic.\n",
    "\n",
    "You can see the keywords for each topic and the weightage(importance) of each keyword using `lda_model.print_topics()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.008*\"use\" + 0.008*\"model\" + 0.008*\"sample\" + 0.007*\"method\" + 0.007*\"set\" '\n",
      "  '+ 0.007*\"distribution\" + 0.007*\"time\" + 0.006*\"problem\" + 0.006*\"show\" + '\n",
      "  '0.005*\"matrix\"'),\n",
      " (1,\n",
      "  '0.010*\"use\" + 0.009*\"kernel\" + 0.008*\"loss\" + 0.008*\"method\" + 0.007*\"set\" '\n",
      "  '+ 0.007*\"datum\" + 0.007*\"result\" + 0.006*\"feature\" + 0.006*\"problem\" + '\n",
      "  '0.006*\"show\"'),\n",
      " (2,\n",
      "  '0.011*\"set\" + 0.009*\"use\" + 0.008*\"training\" + 0.007*\"error\" + '\n",
      "  '0.007*\"datum\" + 0.007*\"utterance\" + 0.007*\"correlation\" + 0.006*\"view\" + '\n",
      "  '0.006*\"test\" + 0.006*\"change\"'),\n",
      " (3,\n",
      "  '0.015*\"model\" + 0.013*\"function\" + 0.011*\"feature\" + 0.009*\"use\" + '\n",
      "  '0.006*\"problem\" + 0.006*\"loss\" + 0.006*\"set\" + 0.005*\"datum\" + '\n",
      "  '0.005*\"parameter\" + 0.005*\"linear\"'),\n",
      " (4,\n",
      "  '0.014*\"model\" + 0.010*\"set\" + 0.009*\"class\" + 0.008*\"use\" + 0.007*\"image\" + '\n",
      "  '0.007*\"component\" + 0.007*\"label\" + 0.006*\"edge\" + 0.006*\"datum\" + '\n",
      "  '0.005*\"show\"'),\n",
      " (5,\n",
      "  '0.012*\"image\" + 0.011*\"use\" + 0.009*\"set\" + 0.009*\"point\" + 0.008*\"learn\" + '\n",
      "  '0.007*\"function\" + 0.006*\"example\" + 0.006*\"feature\" + 0.006*\"time\" + '\n",
      "  '0.006*\"problem\"'),\n",
      " (6,\n",
      "  '0.027*\"map\" + 0.013*\"model\" + 0.011*\"datum\" + 0.009*\"use\" + 0.009*\"prior\" + '\n",
      "  '0.008*\"gp\" + 0.007*\"noise\" + 0.007*\"correlation\" + 0.007*\"posterior\" + '\n",
      "  '0.006*\"method\"'),\n",
      " (7,\n",
      "  '0.008*\"problem\" + 0.008*\"datum\" + 0.008*\"set\" + 0.007*\"model\" + 0.007*\"use\" '\n",
      "  '+ 0.006*\"figure\" + 0.006*\"concept\" + 0.006*\"show\" + 0.006*\"sample\" + '\n",
      "  '0.006*\"program\"'),\n",
      " (8,\n",
      "  '0.011*\"kernel\" + 0.009*\"learn\" + 0.009*\"datum\" + 0.007*\"taxonomy\" + '\n",
      "  '0.007*\"feature\" + 0.007*\"class\" + 0.007*\"use\" + 0.007*\"level\" + '\n",
      "  '0.006*\"machine\" + 0.006*\"give\"'),\n",
      " (9,\n",
      "  '0.021*\"model\" + 0.009*\"network\" + 0.008*\"state\" + 0.007*\"learn\" + '\n",
      "  '0.007*\"input\" + 0.007*\"use\" + 0.006*\"function\" + 0.006*\"time\" + '\n",
      "  '0.006*\"neural\" + 0.006*\"parameter\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Model Perplexity and Coherence Score\n",
    "\n",
    "Let's calculate the baseline coherence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score:  0.27186389530360716\n",
      "CPU times: user 358 ms, sys: 59.8 ms, total: 417 ms\n",
      "Wall time: 3.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('Coherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** **\n",
    "#### Step 6: Hyperparameter tuning\n",
    "#### Do not do that during the labs as it will take a long time! So skip to Step 7 for now\n",
    "** **\n",
    "First, let's differentiate between model hyperparameters and model parameters :\n",
    "\n",
    "- `Model hyperparameters` can be thought of as settings for a machine learning algorithm that are tuned by the data scientist before training. Examples would be the number of trees in the random forest, or in our case, number of topics K\n",
    "\n",
    "- `Model parameters` can be thought of as what the model learns during training, such as the weights for each word in a given topic.\n",
    "\n",
    "Now that we have the baseline coherence score for the default LDA model, let's perform a series of sensitivity tests to help determine the following model hyperparameters: \n",
    "- Number of Topics (K)\n",
    "- Dirichlet hyperparameter alpha: Document-Topic Density\n",
    "- Dirichlet hyperparameter beta: Word-Topic Density\n",
    "\n",
    "We'll perform these tests in sequence, one parameter at a time by keeping others constant and run them over the two difference validation corpus sets. We'll use `C_v` as our choice of metric for performance comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supporting function\n",
    "def compute_coherence_values(corpus, dictionary, k, a, b):\n",
    "    \n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=k, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=a,\n",
    "                                           eta=b)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "    \n",
    "    return coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call the function, and iterate it over the range of topics, alpha, and beta parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 151/540 [39:55<1:57:47, 18.17s/it]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "grid = {}\n",
    "grid['Validation_Set'] = {}\n",
    "\n",
    "# Topics range\n",
    "min_topics = 2\n",
    "max_topics = 11\n",
    "step_size = 1\n",
    "topics_range = range(min_topics, max_topics, step_size)\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = list(np.arange(0.01, 1, 0.3))\n",
    "alpha.append('symmetric')\n",
    "alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "beta = list(np.arange(0.01, 1, 0.3))\n",
    "beta.append('symmetric')\n",
    "\n",
    "# Validation sets\n",
    "num_of_docs = len(corpus)\n",
    "corpus_sets = [gensim.utils.ClippedCorpus(corpus, int(num_of_docs*0.75)), \n",
    "               corpus]\n",
    "\n",
    "corpus_title = ['75% Corpus', '100% Corpus']\n",
    "\n",
    "model_results = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "\n",
    "# Can take a long time to run\n",
    "if 1 == 1:\n",
    "    pbar = tqdm.tqdm(total=(len(beta)*len(alpha)*len(topics_range)*len(corpus_title)))\n",
    "    \n",
    "    # iterate through validation corpuses\n",
    "    for i in range(len(corpus_sets)):\n",
    "        # iterate through number of topics\n",
    "        for k in topics_range:\n",
    "            # iterate through alpha values\n",
    "            for a in alpha:\n",
    "                # iterare through beta values\n",
    "                for b in beta:\n",
    "                    # get the coherence score for the given parameters\n",
    "                    cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=id2word, \n",
    "                                                  k=k, a=a, b=b)\n",
    "                    # Save the model results\n",
    "                    model_results['Validation_Set'].append(corpus_title[i])\n",
    "                    model_results['Topics'].append(k)\n",
    "                    model_results['Alpha'].append(a)\n",
    "                    model_results['Beta'].append(b)\n",
    "                    model_results['Coherence'].append(cv)\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "    pd.DataFrame(model_results).to_csv('../results/lda_tuning_results.csv', index=False)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** **\n",
    "#### Step 7: Final Model\n",
    "** **\n",
    "\n",
    "Based on external evaluation (Code to be added from Excel based analysis), let's train the final model with parameters yielding highest coherence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 8\n",
    "\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=num_topics, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=0.01,\n",
    "                                           eta=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.007*\"time\" + 0.006*\"method\" + 0.006*\"use\" + 0.005*\"distribution\" + '\n",
      "  '0.005*\"model\" + 0.005*\"problem\" + 0.005*\"set\" + 0.005*\"sample\" + '\n",
      "  '0.004*\"matrix\" + 0.004*\"show\"'),\n",
      " (1,\n",
      "  '0.007*\"error\" + 0.005*\"neural\" + 0.005*\"code\" + 0.003*\"use\" + '\n",
      "  '0.003*\"response\" + 0.003*\"optimal\" + 0.003*\"function\" + 0.003*\"noise\" + '\n",
      "  '0.003*\"utterance\" + 0.003*\"rate\"'),\n",
      " (2,\n",
      "  '0.004*\"profile\" + 0.003*\"rois\" + 0.003*\"energy\" + 0.003*\"optimization\" + '\n",
      "  '0.003*\"functional\" + 0.002*\"structural\" + 0.002*\"fig\" + 0.002*\"roi\" + '\n",
      "  '0.002*\"brain\" + 0.002*\"location\"'),\n",
      " (3,\n",
      "  '0.013*\"model\" + 0.009*\"use\" + 0.009*\"function\" + 0.007*\"set\" + '\n",
      "  '0.007*\"feature\" + 0.007*\"datum\" + 0.006*\"problem\" + 0.006*\"learn\" + '\n",
      "  '0.006*\"method\" + 0.005*\"training\"'),\n",
      " (4,\n",
      "  '0.013*\"model\" + 0.007*\"class\" + 0.007*\"set\" + 0.007*\"use\" + 0.006*\"learn\" + '\n",
      "  '0.006*\"image\" + 0.005*\"object\" + 0.005*\"label\" + 0.004*\"show\" + '\n",
      "  '0.004*\"component\"'),\n",
      " (5,\n",
      "  '0.004*\"model\" + 0.004*\"use\" + 0.004*\"machine\" + 0.003*\"pv_tree\" + '\n",
      "  '0.003*\"user\" + 0.003*\"figure\" + 0.003*\"parallel\" + 0.003*\"attribute\" + '\n",
      "  '0.003*\"spike\" + 0.002*\"filter\"'),\n",
      " (6,\n",
      "  '0.009*\"state\" + 0.008*\"model\" + 0.006*\"input\" + 0.006*\"neuron\" + '\n",
      "  '0.005*\"concept\" + 0.004*\"time\" + 0.004*\"map\" + 0.004*\"velocity\" + '\n",
      "  '0.003*\"class\" + 0.003*\"population\"'),\n",
      " (7,\n",
      "  '0.004*\"set\" + 0.004*\"player\" + 0.004*\"show\" + 0.004*\"source\" + '\n",
      "  '0.004*\"program\" + 0.003*\"game\" + 0.003*\"regret\" + 0.003*\"learn\" + '\n",
      "  '0.003*\"network\" + 0.003*\"result\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** **\n",
    "#### Step 8: Visualize Results\n",
    "** **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory 'results': File exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/pyLDAvis/_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el2711400031015764323834778114\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el2711400031015764323834778114_data = {\"mdsDat\": {\"x\": [0.13754379183757645, 0.07318458404023936, 0.06534837867387995, -0.0020925313047511066, -0.04543828571839194, -0.04589348639078766, -0.0642475263516399, -0.11840492478612531], \"y\": [-0.004543480086905064, -0.046892141428694405, 0.07065232225191409, -0.03195343353743566, 0.014392460491596978, -0.005014079505883849, 0.0035882745108988113, -0.0002299226954908023], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [49.94012729502103, 17.21439584548707, 16.301683850048562, 6.297176960811872, 4.181910856803355, 2.795634043708087, 2.606952509858184, 0.662118638261859]}, \"tinfo\": {\"Term\": [\"state\", \"model\", \"error\", \"input\", \"neural\", \"optimization\", \"use\", \"time\", \"class\", \"map\", \"optimal\", \"neuron\", \"image\", \"machine\", \"show\", \"figure\", \"noise\", \"set\", \"code\", \"fig\", \"object\", \"network\", \"datum\", \"kernel\", \"label\", \"result\", \"rate\", \"training\", \"energy\", \"experiment\", \"reward\", \"pre_image\", \"timestamp\", \"mdp\", \"ulsif\", \"mean_field\", \"mdn\", \"policy\", \"timeline_tree\", \"agent\", \"grift\", \"hme\", \"terrain\", \"apprenticeship_learne\", \"reinforcement_learne\", \"spline\", \"low_resolution\", \"refinement\", \"gpr\", \"gaussian_processe\", \"planning\", \"relational\", \"planner\", \"robot\", \"svr\", \"expert\", \"mgp\", \"latent\", \"polymom\", \"center_location\", \"regression\", \"feature\", \"observation\", \"training\", \"function\", \"mixture\", \"linear\", \"approach\", \"likelihood\", \"importance\", \"classification\", \"parameter\", \"selection\", \"datum\", \"layer\", \"problem\", \"model\", \"use\", \"give\", \"solve\", \"method\", \"optimal\", \"first\", \"solution\", \"kernel\", \"follow\", \"learn\", \"set\", \"result\", \"value\", \"sample\", \"state\", \"base\", \"network\", \"point\", \"figure\", \"show\", \"matrix\", \"number\", \"input\", \"example\", \"image\", \"tensor\", \"nf\", \"sls\", \"tensor_decomposition\", \"total_independence\", \"matroid\", \"fnj\", \"laplace\", \"plant\", \"classication_calibration\", \"waveform\", \"classication_calibrate\", \"lancaster_interaction\", \"add_delete\", \"gcbn\", \"arm\", \"wishart\", \"bic\", \"tensor_pow\", \"markov_chain\", \"sparse_pca\", \"admission\", \"sampler\", \"privacy\", \"returning_time\", \"hawke\", \"gaussian_integral\", \"dag\", \"copula\", \"symmetric_phase\", \"student\", \"item\", \"surrogate\", \"comp\", \"bandit\", \"attractor\", \"regret\", \"event\", \"lower_bound\", \"mix\", \"time\", \"interval\", \"graph\", \"distribution\", \"sparse\", \"marginal\", \"variable\", \"method\", \"matrix\", \"sample\", \"loss\", \"general\", \"controller\", \"case\", \"rank\", \"problem\", \"vector\", \"use\", \"set\", \"consider\", \"show\", \"analysis\", \"result\", \"probability\", \"model\", \"control\", \"give\", \"also\", \"large\", \"value\", \"small\", \"function\", \"learn\", \"algorithm\", \"figure\", \"datum\", \"network\", \"taxonomy\", \"clutter\", \"cps\", \"feature_congestion\", \"mallow\", \"eccentricity\", \"optical_flow\", \"query\", \"mds\", \"rank_aggregation\", \"mkl\", \"foveate\", \"treecutter\", \"morph\", \"quadrant\", \"fixation\", \"coset_permutation\", \"luce\", \"forest\", \"codeword\", \"facial\", \"mog\", \"adaboost\", \"patch\", \"peripheral_architecture\", \"cd_mcboost\", \"distinctiveness\", \"pifc\", \"blink\", \"engine\", \"category\", \"object\", \"topic\", \"semantic\", \"net\", \"edge\", \"label\", \"class\", \"permutation\", \"contribution\", \"node\", \"face\", \"distance\", \"flow\", \"image\", \"target\", \"model\", \"human\", \"graph\", \"visual\", \"component\", \"learn\", \"set\", \"use\", \"level\", \"cluster\", \"representation\", \"show\", \"point\", \"number\", \"example\", \"result\", \"feature\", \"space\", \"datum\", \"input\", \"network\", \"figure\", \"base\", \"give\", \"low_approximate\", \"mismatch_error\", \"std\", \"orbitope\", \"sc\", \"anarchy\", \"hedge\", \"bump\", \"cann\", \"player\", \"smt\", \"standard_shrinkage\", \"synaptic_depression\", \"orbit\", \"autocorrelation\", \"morphology\", \"border\", \"fast_convergence\", \"lexeme\", \"denotation\", \"assembly\", \"dynamic_population\", \"sancetta\", \"inhibition\", \"spectrogram\", \"continuation\", \"stf\", \"lag_parameter\", \"tense\", \"shrinkage\", \"quantizer\", \"wave\", \"realize\", \"source\", \"program\", \"game\", \"regret\", \"seed\", \"grammar\", \"stem\", \"feedback\", \"estimator\", \"redundancy\", \"group\", \"action\", \"eq\", \"cost\", \"shape\", \"show\", \"dynamic\", \"set\", \"algorithm\", \"network\", \"rule\", \"learn\", \"result\", \"time\", \"datum\", \"large\", \"number\", \"figure\", \"input\", \"order\", \"solution\", \"use\", \"model\", \"neural\", \"distribution\", \"see\", \"vcd\", \"velocity\", \"rtd\", \"microcircuit\", \"tsmin\", \"phase_tune\", \"recursive_teache\", \"rtd_vcd\", \"cortical\", \"disparity\", \"spatial_frequency\", \"temporal_frequency\", \"preferred\", \"liquid\", \"spatio_temporal\", \"readout\", \"grating\", \"cby\", \"tuning\", \"spike_train\", \"grate\", \"synapsis\", \"readout_neuron\", \"center_frequencie\", \"sine_wave\", \"dendritic\", \"associative\", \"opm\", \"teach\", \"photosensor\", \"tune\", \"concept\", \"synaptic\", \"neuron\", \"filter\", \"spike\", \"population\", \"cell\", \"state\", \"circuit\", \"stimulus\", \"response\", \"motion\", \"input\", \"map\", \"model\", \"fig\", \"time\", \"position\", \"neural\", \"class\", \"phase\", \"activity\", \"size\", \"output\", \"show\", \"example\", \"unit\", \"use\", \"learn\", \"gnkr\", \"eeg\", \"metabolic_constraint\", \"nystrm\", \"alertness\", \"utterance\", \"gnkr_cs\", \"session\", \"metabolic_cost\", \"coherence\", \"gnkr_u\", \"jol\", \"metabolic\", \"receptive_field\", \"qr\", \"scalp\", \"ktotal\", \"tuning_curve\", \"sonorant\", \"voc\", \"gol\", \"subsample\", \"knn\", \"monotonic\", \"hz\", \"duration\", \"fric\", \"site\", \"language\", \"pitch\", \"segment\", \"misspecifie\", \"phonetic\", \"code\", \"response\", \"error\", \"neural\", \"neuron\", \"correlation\", \"change\", \"frequency\", \"speaker\", \"noise\", \"rate\", \"optimal\", \"kernel\", \"input\", \"test\", \"function\", \"use\", \"network\", \"set\", \"performance\", \"result\", \"training\", \"datum\", \"time\", \"pv_tree\", \"cricket\", \"chip\", \"mud\", \"cdma\", \"mmse\", \"receiver\", \"inner_loop\", \"top_attribute\", \"communication_cost\", \"voting\", \"decentralize\", \"cluster_center\", \"best_attribute\", \"global_vote\", \"outer_loop\", \"mjolsness\", \"centralized_gp\", \"ber\", \"parallelize\", \"avlsi\", \"mia\", \"intrinsic_reliability\", \"gbdt\", \"sound\", \"pass_delay\", \"multiuser_detection\", \"current_injection\", \"spread\", \"interference\", \"parallel\", \"distance_measure\", \"khz\", \"attribute\", \"communication\", \"user\", \"decision_tree\", \"spike\", \"histogram\", \"gain\", \"filter\", \"frequency\", \"machine\", \"circuit\", \"neuron\", \"figure\", \"model\", \"use\", \"experiment\", \"current\", \"local\", \"objective\", \"datum\", \"point\", \"show\", \"time\", \"order\", \"system\", \"input\", \"rois\", \"functional_connectivity\", \"fmri\", \"anatomical\", \"across_subject\", \"structural_connectivity\", \"profile\", \"working_memory\", \"roi\", \"penetrate\", \"anatomical_constraint\", \"anatomic\", \"fiber\", \"gyrus\", \"parcellation\", \"precuneus\", \"simulated_anneale\", \"hammer\", \"connectomic\", \"brain\", \"structural\", \"neuroimage\", \"yellow\", \"pole\", \"individualized\", \"volumetric\", \"occipital\", \"granger\", \"sporn\", \"buckner\", \"energy\", \"connectivity\", \"functional\", \"activate\", \"autoregressive\", \"landmark\", \"variability\", \"imaging\", \"individual\", \"location\", \"optimization\", \"fig\", \"consistency\", \"region\", \"subject\", \"optimize\", \"activation\", \"right\", \"similar\", \"human\", \"pattern\", \"use\", \"map\", \"group\"], \"Freq\": [479.0, 1853.0, 356.0, 546.0, 375.0, 245.0, 1326.0, 615.0, 487.0, 304.0, 362.0, 122.0, 513.0, 254.0, 759.0, 598.0, 249.0, 1143.0, 137.0, 147.0, 193.0, 615.0, 868.0, 430.0, 227.0, 769.0, 231.0, 617.0, 63.0, 279.0, 100.8485141058325, 77.29990916183662, 50.92158693692515, 44.909541563730514, 42.848430876060796, 42.79559125550863, 47.78768307019433, 138.72834640100209, 40.12451645656005, 47.21438581797425, 41.722642207360366, 39.58902552017395, 35.06961746193719, 32.239499758711446, 31.013567888899445, 30.928471429496323, 29.26402606950131, 28.31745997707102, 27.284193048598937, 42.19564038938171, 31.075654846157942, 33.134911229169894, 29.195750034522764, 61.14812012287237, 25.25734937352512, 151.1958524516262, 24.35179297541006, 91.50958012419862, 22.471759168668253, 25.379394868782764, 191.9536408227938, 661.5259063047778, 158.41358015029041, 504.2340891009018, 832.5607331736074, 239.51506110116796, 352.87548782308096, 362.4473547185069, 133.71576855094514, 66.1456001706578, 224.39373872190276, 450.23054570164385, 102.92397012431839, 608.1343156913592, 146.0546879794464, 593.0430491719382, 1161.9981541094799, 850.0959839815561, 463.9063489160448, 164.1170235426659, 558.9496854887418, 262.6508494551802, 327.0102275103908, 233.71750502891572, 298.65643659901787, 312.45504315492786, 561.1419573258709, 684.5860175295687, 470.3063551346149, 340.6612421651349, 398.05696988336797, 315.27537066704025, 336.6547186508478, 377.63197069675715, 324.2967509449347, 362.8345980286017, 427.44188317956537, 333.1043863311478, 340.0149336825638, 327.21722165815856, 315.51764497647054, 311.6387406210066, 83.04243860748994, 31.333341029433655, 24.598165314009844, 25.40712088261323, 17.940030251140062, 17.942914898616834, 17.11426146747456, 21.563608803238992, 18.41455568741706, 17.681593998198547, 40.23630060686588, 16.94024144936391, 14.939261355034528, 14.943500323195643, 15.564581413938027, 27.105753979076898, 13.388432630055737, 13.383120024635284, 17.171672807237066, 20.172573244749696, 13.258153835196765, 12.582550683908332, 22.41668261870454, 19.404493705227893, 11.893191265750897, 11.893593300755688, 11.88782493215008, 11.874510533247173, 11.845865075981845, 11.152560341959422, 31.30148207117381, 29.885340630887633, 35.657770345852306, 26.82995426039851, 22.40069755869838, 24.386837559072113, 62.183787995324685, 51.63071372099316, 48.13742230088464, 33.05122363603455, 221.80764031423072, 48.247528016712884, 91.39333927898849, 175.01358185428572, 64.39659607247795, 60.06986200239127, 123.7034363950851, 202.5290057978529, 143.03031511203784, 159.1835702604795, 115.96100551351044, 74.49844256115573, 35.580890877839366, 114.61391775386285, 54.86214881157563, 164.8754225264655, 102.25593233691636, 188.93104808594543, 164.07828901023805, 88.6693872315965, 126.81950781894717, 84.82288675377652, 126.50951474520693, 94.60480971882613, 171.33386105909838, 61.85942911777269, 101.44601521915405, 89.1040370945642, 83.65196813945411, 88.72410104616557, 74.17532498983972, 104.36166200330048, 92.72562029320618, 77.80427450727916, 81.65951970962732, 84.8219900489732, 80.09067907535554, 80.3183957836279, 48.352674264932226, 44.56813092047648, 41.74999626018435, 29.18202350587384, 28.533204645012464, 26.9512031663107, 55.699459657003985, 24.142063650280864, 23.333465622661844, 23.31074354087115, 22.670647882130336, 21.94056393699261, 19.743050369162507, 18.992581290187545, 16.800422350851395, 16.756873009934974, 16.75544662953996, 21.12772536642802, 15.920850933171465, 33.699066694365136, 15.898528869498934, 20.50336726259899, 26.52929282850961, 13.866967555043766, 14.458989983755563, 13.137462583498115, 13.135201077558172, 13.080244202412498, 30.68258620822163, 56.4914569327194, 148.6188577611374, 42.871001420223855, 35.039699345928256, 50.01010723035385, 108.08583592004211, 136.87401702607235, 222.4307062098866, 48.58801825778246, 49.06827860687185, 101.58583625015012, 65.67363422776151, 92.99078028463964, 52.01452082396984, 181.2408265473273, 85.61067759404227, 400.5870983160154, 58.69594625510126, 88.82668290680647, 48.57574401763053, 118.76481785247984, 189.40591216084886, 210.82460860106724, 204.08006452160734, 93.34838244655037, 96.40937021173536, 84.79848642122154, 121.18676614711318, 102.19646039858902, 103.1551003098263, 97.64150321214414, 107.52814750257292, 108.24039028874766, 87.6396045786535, 105.9432687005651, 92.96492648205547, 95.62167137632473, 93.65681045137444, 85.71926496846814, 83.73855069388765, 29.846976966546446, 15.673781622766192, 27.356936628521023, 12.47265903086824, 11.109304074229852, 10.600201662815493, 10.593411461919628, 16.704014840195153, 10.103633234370305, 48.104301599899905, 9.10161808306573, 8.912370121436956, 8.070720010154302, 8.449587330765974, 11.878980360306489, 7.570779185296515, 8.082492899640487, 9.58439262401381, 6.5551043375096425, 6.555332055595381, 6.544595418945785, 6.540903132841316, 6.914987695920088, 6.034752923752776, 6.424767586847249, 5.945383063354118, 5.532992726272477, 5.914942034964191, 5.536251602508405, 17.61507017089529, 7.050829666851681, 7.473809911518744, 11.10895368658007, 43.91219327374292, 41.33268683731832, 40.413020238768816, 37.50043001614908, 15.861170564427171, 12.229246018256488, 8.069747464163129, 11.752491096467713, 26.962943676250113, 9.094199624236891, 26.911620357212076, 27.83572474750389, 20.57568722216904, 27.936452047428737, 16.880103271851375, 46.937864502438806, 21.66591060054205, 48.5600956140824, 32.697134480659635, 35.54723777618098, 18.927006925959915, 37.30991401720359, 35.20651187946565, 31.550682356151647, 34.210787440279596, 27.961769418889556, 30.067207464751174, 30.42955844682285, 29.467774846130148, 25.34239334095363, 24.15808579562127, 29.58554304947107, 30.218344500441514, 24.26333221517618, 24.953646037443473, 23.939489987960588, 19.962008927810068, 27.776040564981002, 9.739166222701751, 9.348610735938351, 8.033021253604662, 7.663804832309768, 7.183295093863306, 7.180776911308334, 23.400972247762564, 8.515777777987571, 8.084777443904276, 5.941314855586883, 7.629828496103376, 5.500640109703928, 5.094867509056065, 5.07656196466361, 5.065734904870512, 5.051659187046711, 11.091801568502762, 9.776085164367375, 4.653728733465482, 6.777727278391941, 4.647361939824263, 4.240095532581234, 4.238887525078546, 6.336203686700465, 4.62536261094054, 5.008409908002059, 8.746455002033004, 3.811988295452963, 23.053102093173152, 36.78561796425385, 9.363270654111812, 44.22569116558134, 25.91442899096824, 17.422886976022685, 26.03160391841978, 17.526131110544565, 69.0690369737187, 12.340463654538093, 19.758473165926382, 19.50885308801614, 14.959942409429056, 46.48168388350089, 30.113842935564, 61.90326609003598, 20.26812631041386, 34.211262160253185, 17.146330671204502, 25.96081935956627, 26.42685101107291, 14.092496705954149, 11.670713509759507, 17.26004540428918, 17.276109563672918, 20.441047813604225, 16.990438293152636, 14.633031455057674, 18.218722678855727, 15.587714743566528, 9.273864715646251, 12.257394748968654, 7.038283932277093, 8.631440542906072, 7.082771380645228, 14.921787862170982, 5.083509217993183, 11.60756593052557, 4.461062845552936, 13.231868990316398, 4.439620965367172, 5.158168265784142, 3.8188896063566906, 11.162183562165367, 4.503197415847252, 3.524897791912481, 3.497807499951804, 4.4633221500869915, 3.1641128237289577, 3.161567984502824, 3.2837109400912237, 3.970993846563106, 2.8269676608372416, 4.128207924151577, 2.5519297535874395, 6.352111271341323, 2.523205836115023, 3.5263525445322914, 10.173898949514768, 3.475488856760015, 11.08066927472813, 3.9454855792715007, 4.413936081780255, 23.328045938230556, 16.214804485649815, 35.07520433379352, 27.321377082517493, 14.398010725538422, 14.552586992120093, 13.041077657689046, 10.037195529907654, 7.458158935984338, 15.965016691038505, 14.690339277835307, 16.197946806273862, 13.881322311082227, 14.115087667945833, 12.616842307556508, 15.992772227682202, 16.594324320716012, 13.799457799849858, 14.63393760108263, 10.942159976067426, 12.110573953644113, 11.143909341872336, 10.024972599105755, 9.695787505564548, 16.567991837762435, 8.15405819515471, 10.389636513022536, 6.926734281365302, 5.6593950838070874, 5.343336068035685, 8.45222452633416, 6.768900893822852, 5.272811304831877, 5.272609292461147, 4.96436366627321, 5.343414067256607, 5.056209151771167, 4.336983666542239, 4.3350715633387304, 5.025879800033399, 4.7331032711341265, 3.4432194930024225, 3.442741677631098, 3.0839051394938912, 2.803309395404175, 3.2268207551761283, 2.8026009492429336, 2.7667720912847735, 6.883047983903949, 2.48925338840311, 2.4917583418001645, 2.484795929328401, 6.2093563676103445, 3.756632707862733, 15.594379749536873, 8.367298525679185, 3.119865305493026, 13.995002918827973, 7.7441425485056365, 16.236991201448163, 8.622128714173213, 12.267176522190278, 8.86250660097792, 9.842842895421425, 11.896728481327141, 10.904658073871582, 17.18895317498619, 7.541441091133061, 11.845839320558309, 15.778817044013543, 20.248164546740213, 17.434026727119424, 11.30256857424454, 9.28556146890657, 9.219261569978393, 8.645754622075584, 11.61087648758012, 10.521338478120088, 8.373269674670684, 8.190866532538175, 8.007921323877538, 8.012541795712517, 7.973276202297309, 4.210303815637882, 1.654720432182157, 1.8765588553300467, 1.8771627158296424, 1.4326237614002648, 1.4321059834453365, 4.52982711424172, 0.8769103406990956, 2.6546300448624964, 0.6545560636266632, 0.6544688409158412, 0.6543094314353602, 1.6544459371804525, 0.543436717262405, 0.5432360123890144, 0.5430194164498451, 0.9682030171304121, 0.43239041279242163, 0.4322565857900331, 2.642585899689065, 3.0580259610847063, 0.5428404103635831, 0.42800266149765503, 0.3213979455430478, 0.32139812369400944, 0.32139409748227626, 0.32138002355630624, 0.3213521963760971, 0.3213519469647508, 0.3213375523670498, 4.195557476678203, 1.269949700177355, 3.706179635451732, 0.6510224036722203, 0.42759865074683395, 0.5437692894776059, 0.5433456464908114, 0.7526823259051858, 2.013164157595666, 2.404606144291422, 3.9449728994006357, 2.8040639266158673, 1.1713625969912462, 2.1913852394602777, 1.1921565197553492, 1.4334777458500114, 1.1876305589445375, 1.3054345213218734, 1.5361080920012558, 1.2842174543936686, 1.3665497075372632, 2.0194973530218006, 1.2973825254177773, 1.1636941957377667], \"Total\": [479.0, 1853.0, 356.0, 546.0, 375.0, 245.0, 1326.0, 615.0, 487.0, 304.0, 362.0, 122.0, 513.0, 254.0, 759.0, 598.0, 249.0, 1143.0, 137.0, 147.0, 193.0, 615.0, 868.0, 430.0, 227.0, 769.0, 231.0, 617.0, 63.0, 279.0, 105.63516328641235, 81.53812532752997, 53.97417134257512, 47.994181375621054, 45.970869779124, 45.980681232929776, 51.35667143848163, 149.12416550535, 43.141299146828636, 50.82014194277799, 45.03887092867066, 42.85406770572646, 38.13502430807799, 35.24913720016855, 34.14611823632194, 34.10656482019636, 32.289843915683214, 31.308919801400272, 30.276951573041437, 46.889365327009834, 34.539100118110206, 36.84531512206542, 32.56623383450786, 68.35680298823446, 28.258791950127225, 169.2206051885772, 27.330097798319727, 103.4895786508419, 25.417817722319917, 28.775783582310588, 217.7557676780396, 791.4099890237674, 185.00099044181482, 617.5702381455877, 1044.8448712415095, 289.3575725976542, 443.8842381886091, 466.1417394337733, 162.20684800678953, 76.84220795818501, 287.9186750605595, 616.0512705484315, 124.32958977544494, 868.1799634589457, 182.7052949530753, 865.7152718383708, 1853.2680614446658, 1326.9592107182925, 686.5907538457676, 211.4224781251666, 861.8059563194628, 362.856134617929, 476.9192680659233, 322.78837345313104, 430.28509150699904, 454.1018811453341, 904.6885953686628, 1143.1932042981707, 769.0707091456648, 517.9132049861155, 643.0072437274606, 479.4484267251806, 521.1466990255616, 615.1269070467994, 507.25282018623363, 598.5088122397243, 759.1618978057443, 534.1345846484686, 564.3315109569832, 546.5957095524544, 517.0063896978584, 513.6714703544704, 92.49209526447969, 35.22357752926236, 27.917675494560868, 29.581953871381998, 21.10558167162594, 21.11814595838165, 20.332874944288605, 25.648166410537925, 21.920870296101885, 21.136482247495195, 48.27325997969324, 20.387653301513527, 18.08985716576943, 18.101185336371096, 18.86188014868929, 33.38186826368365, 16.5947907510758, 16.595270837571537, 21.302293622462212, 25.10343245624804, 16.599572289682218, 15.794176811278673, 28.209518425148982, 24.54240273023169, 15.056483623131227, 15.057614748378256, 15.074538460306012, 15.08620956362898, 15.087545698573837, 14.295185934468135, 40.61902021726435, 38.824275681159754, 48.60967283953285, 36.41388253932741, 30.821513954992117, 33.96694757061071, 103.21807808689331, 88.39327473293352, 81.50604829395394, 51.549081581809105, 615.7591224519531, 88.47241983899137, 222.71943703870062, 576.4308071478976, 139.7414693698909, 132.1269405030942, 388.83699391296057, 861.8059563194628, 534.1345846484686, 643.0072437274606, 394.6025209333932, 198.97196325490603, 64.11570504125422, 462.326466885895, 133.2121704215187, 865.7152718383708, 392.16742963619873, 1326.9592107182925, 1143.1932042981707, 351.4188190637112, 759.1618978057443, 335.24418074511146, 769.0707091456648, 462.57927822147667, 1853.2680614446658, 186.18618461843832, 686.5907538457676, 496.9885274229638, 423.0213225321263, 517.9132049861155, 315.67569275339326, 1044.8448712415095, 904.6885953686628, 431.2559257106995, 598.5088122397243, 868.1799634589457, 615.1269070467994, 84.7032955623276, 51.69066191311839, 47.924453930770326, 45.053704550845644, 32.46016814234168, 31.779363028956702, 30.300760877050802, 62.7384556631777, 27.34784881465794, 26.574794275732422, 26.56807608278511, 25.886357036200643, 25.127376442455738, 22.926742966686536, 22.18406176704491, 19.986319181591277, 19.95375441568716, 19.953727367635107, 25.442805177121333, 19.289738671247836, 40.85697535218929, 19.30111944884131, 25.039411054047758, 32.47607482145511, 17.034846900832974, 17.815039996942815, 16.295024185078667, 16.298767524198773, 16.26280840190746, 38.36637356031304, 70.8939771845885, 193.11348270625203, 56.18392625104961, 45.595931811118284, 67.46053458963267, 163.5417509021841, 227.66474407557638, 487.67946810214806, 74.36515510500325, 80.34691443031693, 207.81545653950516, 117.95147087943894, 191.9719538325761, 88.19107699090242, 513.6714703544704, 181.90894375000042, 1853.2680614446658, 109.52381718143454, 222.71943703870062, 86.02756517080202, 373.49710494749127, 904.6885953686628, 1143.1932042981707, 1326.9592107182925, 300.75619360388527, 320.26753291736964, 261.86702741110906, 759.1618978057443, 507.25282018623363, 564.3315109569832, 517.0063896978584, 769.0707091456648, 791.4099890237674, 442.98314953314724, 868.1799634589457, 546.5957095524544, 615.1269070467994, 598.5088122397243, 521.1466990255616, 686.5907538457676, 33.503093832452905, 19.14853501911858, 34.86447453167489, 16.19308098231668, 14.539034697956398, 14.023433664955668, 14.020849936696896, 22.147792669810638, 13.515735900111968, 65.75683324591685, 12.495942568626631, 12.629138234891222, 11.46479399407719, 12.063315548899181, 17.073322901332176, 10.956434710334207, 11.902360770867196, 14.43247657032435, 9.93269969600374, 9.933788240893744, 9.920703307282043, 9.919217994957082, 10.55170930199066, 9.412796246529565, 10.038956543102906, 9.479559331223102, 8.8989837427425, 9.51399171606024, 8.9068446470562, 28.35620532277855, 11.41253287752852, 12.16110283232783, 18.591244319823506, 81.86893605400616, 86.5553325193719, 84.66389840038366, 103.21807808689331, 34.3324054451771, 23.928662127213165, 13.700325614320818, 24.65565387975479, 91.78595416011171, 16.68417842257514, 107.77143457541271, 137.62408601446012, 84.05944401388628, 165.86808105099138, 59.480911889024235, 759.1618978057443, 126.9796206991218, 1143.1932042981707, 431.2559257106995, 615.1269070467994, 100.6184626735527, 904.6885953686628, 769.0707091456648, 615.7591224519531, 868.1799634589457, 423.0213225321263, 564.3315109569832, 598.5088122397243, 546.5957095524544, 370.4545308928372, 322.78837345313104, 1326.9592107182925, 1853.2680614446658, 375.3528519889086, 576.4308071478976, 384.8370465406979, 23.817516238121048, 33.599033170846035, 13.368867108178158, 12.893918313878263, 11.630754420342614, 11.1103398784354, 10.756054551067423, 10.756722218224136, 35.07457639797169, 12.927002372133645, 12.288341981112769, 9.393055158772206, 12.196528796166023, 8.989559062288343, 8.519389070225445, 8.554381780658176, 8.551641387925821, 8.581506263324583, 18.947518680809157, 16.730835756547858, 8.112035532534076, 11.834406134934467, 8.121430142935505, 7.6554609494437535, 7.654680956104835, 11.537103871028053, 8.50722440144244, 9.390899962205017, 16.495624032094753, 7.223449413341905, 47.611846544948484, 84.7503304692642, 18.962004048957326, 122.21635412109396, 73.65209396051696, 50.80371655903359, 97.37502935602716, 57.28511355857814, 479.4484267251806, 34.49476953611987, 82.27337116432658, 90.64317406072098, 59.85059455092876, 546.5957095524544, 304.5905066029445, 1853.2680614446658, 147.00119802258098, 615.7591224519531, 100.422033892782, 375.3528519889086, 487.67946810214806, 72.0330421652848, 38.95746447031512, 251.20895814126573, 290.1079588735301, 759.1618978057443, 517.0063896978584, 196.17937757199888, 1326.9592107182925, 904.6885953686628, 13.075428044156547, 17.464050748617538, 10.702922929119158, 13.166664251629662, 11.366913992519454, 25.713107570880464, 8.794417411270036, 20.749429983944662, 8.071326671821753, 24.09163957070366, 8.134170388198825, 9.563823583002357, 7.412979398332748, 21.997517113172268, 8.959104159904179, 7.037904362295479, 7.082427604636425, 9.42283098559606, 6.7004797095136475, 6.698433153408958, 7.491743586540401, 9.074292914983703, 6.488793106177321, 9.51008942818601, 6.055961181960129, 15.086190513287038, 6.049325357592939, 8.544369994383858, 25.59204519083296, 8.769091276593233, 29.403316438008822, 10.069408941650444, 11.571642960887058, 137.96593997151436, 90.64317406072098, 356.12234249274064, 375.3528519889086, 122.21635412109396, 142.2573553033388, 118.43209243189578, 69.53146142022524, 39.24610883253221, 249.95557896308296, 231.911662427309, 362.856134617929, 430.28509150699904, 546.5957095524544, 386.9610607027681, 1044.8448712415095, 1326.9592107182925, 615.1269070467994, 1143.1932042981707, 380.8703512031085, 769.0707091456648, 617.5702381455877, 868.1799634589457, 615.7591224519531, 20.82923669210544, 11.86624287981422, 15.665011416549296, 10.591387876303434, 9.294528473024762, 8.972599750433044, 14.272472075601213, 11.54766206814328, 9.061530297860147, 9.062150212484276, 8.722382958185426, 9.482944795073786, 9.36240893812849, 8.069802030151425, 8.074783603908006, 9.39795710910835, 9.042631395247174, 7.029210703393486, 7.029243647205485, 6.7616361300713725, 6.359700916560048, 7.325422005666261, 6.390228011764961, 6.440442514855944, 16.167013093724997, 6.035320798737807, 6.059463266745049, 6.067247995079671, 15.433332654382625, 9.487372160745325, 39.647929348468196, 22.772877350200233, 7.909664070264085, 49.755769728563735, 24.92464144759944, 67.99965442273287, 29.534817638262183, 50.80371655903359, 35.79166544784434, 47.300833090172404, 73.65209396051696, 69.53146142022524, 254.2165867092138, 34.49476953611987, 122.21635412109396, 598.5088122397243, 1853.2680614446658, 1326.9592107182925, 279.3061181777891, 118.25901339995474, 196.64388826928942, 138.82216127423908, 868.1799634589457, 507.25282018623363, 759.1618978057443, 615.7591224519531, 370.4545308928372, 406.92504526737906, 546.5957095524544, 8.16177392807581, 5.441782870484346, 6.204423293785463, 6.640529392000138, 5.204632365646729, 5.20748653370902, 24.440629601730432, 5.127699720212403, 16.0957780598482, 4.378684899040704, 4.378129853064695, 4.378636587189503, 11.519037679832895, 4.259973280156677, 4.260051011195862, 4.2605147156027625, 8.806513416058285, 4.14066147180511, 4.140977379913719, 26.953509729289593, 32.79737701434201, 6.304845774443602, 5.152958607989008, 4.02122909401134, 4.021375850488811, 4.021366474613371, 4.021345824439972, 4.021284776206766, 4.02135172874145, 4.021480594534115, 63.90301621377118, 18.612558060023446, 66.58250331406286, 9.775675215427968, 5.747363820640588, 7.9372757592994505, 8.064684204955203, 13.105036406267093, 58.029209867157114, 90.90061734718108, 245.66067175351836, 147.00119802258098, 29.71935349002951, 112.61610432424511, 46.56252870020727, 84.6436669309185, 53.25928633468129, 102.08165114490994, 192.73224654462385, 109.52381718143454, 156.59415871384684, 1326.9592107182925, 304.5905066029445, 107.77143457541271], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.8196, -7.0855, -7.5029, -7.6286, -7.6755, -7.6768, -7.5664, -6.5007, -7.7412, -7.5785, -7.7022, -7.7547, -7.8759, -7.96, -7.9988, -8.0015, -8.0569, -8.0897, -8.1269, -7.6909, -7.9968, -7.9326, -8.0592, -7.3199, -8.2041, -6.4146, -8.2406, -6.9168, -8.321, -8.1993, -6.176, -4.9387, -6.368, -5.2102, -4.7087, -5.9546, -5.5671, -5.5403, -6.5375, -7.2414, -6.0198, -5.3235, -6.7992, -5.0228, -6.4492, -5.0479, -4.3753, -4.6879, -5.2935, -6.3326, -5.1072, -5.8624, -5.6432, -5.9791, -5.7339, -5.6888, -5.1032, -4.9044, -5.2798, -5.6023, -5.4466, -5.6798, -5.6142, -5.4993, -5.6516, -5.5393, -5.3754, -5.6248, -5.6042, -5.6426, -5.679, -5.6914, -5.9488, -6.9235, -7.1655, -7.1331, -7.4811, -7.4809, -7.5282, -7.2971, -7.455, -7.4956, -6.6734, -7.5384, -7.6641, -7.6639, -7.6231, -7.0684, -7.7737, -7.7741, -7.5249, -7.3638, -7.7835, -7.8358, -7.2583, -7.4026, -7.8922, -7.8921, -7.8926, -7.8937, -7.8962, -7.9565, -6.9245, -6.9708, -6.7942, -7.0786, -7.259, -7.1741, -6.238, -6.424, -6.4941, -6.8701, -4.9663, -6.4918, -5.853, -5.2033, -6.2031, -6.2726, -5.5502, -5.0573, -5.4051, -5.2981, -5.6149, -6.0574, -6.7963, -5.6266, -6.3633, -5.2629, -5.7407, -5.1268, -5.2678, -5.8832, -5.5254, -5.9276, -5.5278, -5.8184, -5.2245, -6.2433, -5.7486, -5.8783, -5.9415, -5.8826, -6.0617, -5.7203, -5.8385, -6.0139, -5.9656, -5.9276, -5.985, -5.9277, -6.4351, -6.5166, -6.582, -6.9401, -6.9626, -7.0196, -6.2937, -7.1297, -7.1638, -7.1647, -7.1926, -7.2253, -7.3309, -7.3696, -7.4923, -7.4948, -7.4949, -7.2631, -7.546, -6.7962, -7.5474, -7.2931, -7.0354, -7.6841, -7.6423, -7.7382, -7.7384, -7.7426, -6.89, -6.2796, -5.3123, -6.5555, -6.7572, -6.4014, -5.6307, -5.3946, -4.909, -6.4303, -6.4204, -5.6928, -6.129, -5.7812, -6.3621, -5.1138, -5.8638, -4.3207, -6.2413, -5.827, -6.4305, -5.5365, -5.0698, -4.9626, -4.9951, -5.7773, -5.7451, -5.8734, -5.5163, -5.6868, -5.6774, -5.7324, -5.6359, -5.6293, -5.8404, -5.6508, -5.7814, -5.7533, -5.774, -5.8626, -5.886, -5.9664, -6.6105, -6.0535, -6.839, -6.9547, -7.0016, -7.0023, -6.5468, -7.0496, -5.4891, -7.154, -7.1751, -7.2742, -7.2284, -6.8877, -7.3382, -7.2728, -7.1024, -7.4822, -7.4822, -7.4839, -7.4844, -7.4288, -7.565, -7.5023, -7.5799, -7.6518, -7.585, -7.6512, -6.4937, -7.4093, -7.3511, -6.9547, -5.5803, -5.6408, -5.6633, -5.7381, -6.5986, -6.8587, -7.2744, -6.8984, -6.068, -7.1549, -6.0699, -6.0362, -6.3384, -6.0326, -6.5364, -5.5137, -6.2868, -5.4797, -5.8752, -5.7916, -6.4219, -5.7432, -5.8013, -5.9109, -5.8299, -6.0317, -5.9591, -5.9471, -5.9792, -6.13, -6.1779, -5.9752, -5.954, -6.1735, -6.1455, -6.187, -5.9593, -5.629, -6.677, -6.7179, -6.8696, -6.9166, -6.9814, -6.9818, -5.8004, -6.8112, -6.8632, -7.1712, -6.9211, -7.2483, -7.3249, -7.3285, -7.3307, -7.3334, -6.547, -6.6732, -7.4155, -7.0395, -7.4169, -7.5086, -7.5089, -7.1069, -7.4216, -7.342, -6.7845, -7.615, -5.8154, -5.3481, -6.7164, -5.1639, -5.6984, -6.0954, -5.6938, -6.0895, -4.7181, -6.4403, -5.9696, -5.9823, -6.2478, -5.1141, -5.5482, -4.8276, -5.9441, -5.4206, -6.1114, -5.6966, -5.6788, -6.3075, -6.4961, -6.1048, -6.1038, -5.9356, -6.1205, -6.2699, -6.0507, -6.2067, -6.3232, -6.0443, -6.5991, -6.395, -6.5928, -5.8476, -6.9244, -6.0988, -7.0551, -5.9678, -7.0599, -6.9099, -7.2105, -6.1379, -7.0457, -7.2906, -7.2983, -7.0546, -7.3986, -7.3994, -7.3615, -7.1714, -7.5112, -7.1326, -7.6136, -6.7017, -7.6249, -7.2902, -6.2306, -7.3047, -6.1452, -7.1779, -7.0657, -5.4008, -5.7645, -4.993, -5.2428, -5.8834, -5.8727, -5.9823, -6.2442, -6.5411, -5.78, -5.8633, -5.7656, -5.9199, -5.9032, -6.0154, -5.7783, -5.7414, -5.9258, -5.8671, -6.1578, -6.0564, -6.1396, -6.2454, -6.2788, -5.6731, -6.3821, -6.1398, -6.5452, -6.7473, -6.8047, -6.3461, -6.5682, -6.818, -6.818, -6.8783, -6.8047, -6.86, -7.0134, -7.0138, -6.866, -6.926, -7.2442, -7.2443, -7.3544, -7.4498, -7.3091, -7.45, -7.4629, -6.5515, -7.5686, -7.5676, -7.5704, -6.6545, -7.157, -5.7337, -6.3562, -7.3428, -5.8419, -6.4336, -5.6933, -6.3262, -5.9736, -6.2987, -6.1938, -6.0043, -6.0914, -5.6363, -6.4602, -6.0086, -5.7219, -5.4725, -5.6221, -6.0555, -6.2521, -6.2593, -6.3235, -6.0286, -6.1272, -6.3555, -6.3776, -6.4001, -6.3996, -6.4045, -5.6725, -6.6064, -6.4806, -6.4803, -6.7506, -6.7509, -5.5994, -7.2414, -6.1338, -7.5339, -7.534, -7.5343, -6.6066, -7.7199, -7.7203, -7.7207, -7.1424, -7.9485, -7.9488, -6.1383, -5.9923, -7.721, -7.9587, -8.2452, -8.2452, -8.2452, -8.2452, -8.2453, -8.2453, -8.2453, -5.6761, -6.8711, -5.8001, -7.5393, -7.9596, -7.7193, -7.7201, -7.3942, -6.4104, -6.2327, -5.7376, -6.079, -6.9519, -6.3255, -6.9343, -6.75, -6.9381, -6.8435, -6.6808, -6.8599, -6.7978, -6.4072, -6.8497, -6.9585], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.648, 0.641, 0.6361, 0.6279, 0.624, 0.6226, 0.6223, 0.6221, 0.6219, 0.6208, 0.6179, 0.6151, 0.6105, 0.6051, 0.5981, 0.5965, 0.596, 0.5939, 0.5903, 0.5889, 0.5887, 0.5882, 0.5851, 0.5829, 0.5821, 0.5817, 0.579, 0.5713, 0.5712, 0.5687, 0.5682, 0.5151, 0.5392, 0.4916, 0.4672, 0.5053, 0.4649, 0.4427, 0.5012, 0.5444, 0.4451, 0.3808, 0.5054, 0.3383, 0.4705, 0.3161, 0.2275, 0.249, 0.3023, 0.4411, 0.2614, 0.3712, 0.317, 0.3715, 0.3292, 0.3205, 0.2167, 0.1816, 0.2025, 0.2754, 0.2148, 0.2752, 0.2574, 0.2064, 0.247, 0.1939, 0.1199, 0.2222, 0.1877, 0.1813, 0.2005, 0.1946, 1.6517, 1.6424, 1.6328, 1.6073, 1.5969, 1.5965, 1.5871, 1.586, 1.5851, 1.5809, 1.5773, 1.5742, 1.5681, 1.5677, 1.5673, 1.5512, 1.5447, 1.5443, 1.5439, 1.5407, 1.5347, 1.5321, 1.5296, 1.5245, 1.5236, 1.5235, 1.5219, 1.52, 1.5175, 1.5112, 1.4989, 1.4977, 1.4496, 1.454, 1.4403, 1.4281, 1.2527, 1.2217, 1.2328, 1.3149, 0.7384, 1.1531, 0.8687, 0.5674, 0.9847, 0.9712, 0.6142, 0.3113, 0.4418, 0.3633, 0.5348, 0.777, 1.1705, 0.3647, 0.8723, 0.1011, 0.4152, -0.1898, -0.1818, 0.3824, -0.03, 0.3851, -0.0454, 0.1723, -0.6217, 0.6575, -0.1528, 0.0407, 0.1387, -0.0049, 0.3111, -0.5443, -0.5185, 0.0469, -0.2325, -0.5664, -0.2792, 1.7607, 1.7471, 1.7413, 1.7377, 1.7074, 1.7062, 1.6968, 1.6949, 1.6892, 1.6838, 1.6831, 1.6813, 1.6783, 1.6644, 1.6586, 1.6403, 1.6393, 1.6392, 1.6281, 1.622, 1.6213, 1.62, 1.614, 1.6116, 1.6082, 1.6052, 1.5985, 1.5981, 1.5961, 1.5904, 1.5868, 1.552, 1.5435, 1.5506, 1.5146, 1.3998, 1.3051, 1.0289, 1.3883, 1.3208, 1.0982, 1.2283, 1.0891, 1.2859, 0.7721, 1.0602, 0.2821, 1.1901, 0.8947, 1.2424, 0.6681, 0.2502, 0.1233, -0.0582, 0.6439, 0.6133, 0.6863, -0.021, 0.2118, 0.1145, 0.1471, -0.1535, -0.1756, 0.1936, -0.2896, 0.0424, -0.0475, -0.0409, 0.0089, -0.2901, 2.6495, 2.5648, 2.5226, 2.504, 2.496, 2.4852, 2.4848, 2.483, 2.4741, 2.4525, 2.4481, 2.4165, 2.414, 2.409, 2.4023, 2.3954, 2.378, 2.3557, 2.3495, 2.3494, 2.3491, 2.3487, 2.3425, 2.3205, 2.3188, 2.2985, 2.2899, 2.2898, 2.2896, 2.289, 2.2835, 2.2782, 2.2501, 2.1421, 2.0259, 2.0255, 1.7526, 1.9929, 2.0938, 2.2358, 2.0241, 1.5401, 2.1582, 1.3776, 1.1669, 1.3577, 0.9838, 1.5055, -0.0183, 0.9968, -0.3937, 0.1857, -0.0859, 1.0943, -0.4233, -0.3189, -0.2062, -0.4688, 0.0485, -0.1671, -0.214, -0.1553, 0.0828, 0.1727, -1.0383, -1.3512, 0.0262, -0.3748, -0.0122, 2.9978, 2.9841, 2.8576, 2.8529, 2.8043, 2.803, 2.7707, 2.7703, 2.7697, 2.757, 2.7557, 2.7164, 2.7053, 2.6832, 2.6603, 2.6526, 2.6508, 2.6445, 2.6389, 2.6371, 2.6187, 2.617, 2.6162, 2.5836, 2.5834, 2.5751, 2.565, 2.5458, 2.54, 2.5352, 2.4491, 2.3398, 2.4688, 2.1579, 2.1298, 2.1042, 1.8551, 1.9901, 1.2369, 2.1465, 1.7479, 1.6383, 1.7879, 0.7098, 0.8604, -0.2247, 1.193, 0.2841, 1.4068, 0.5031, 0.2591, 1.5429, 1.969, 0.4965, 0.3535, -0.4403, -0.241, 0.5787, -1.1138, -0.8867, 3.2336, 3.2231, 3.158, 3.1548, 3.1041, 3.0329, 3.029, 2.9962, 2.9842, 2.9779, 2.9716, 2.9597, 2.9138, 2.8987, 2.8892, 2.8857, 2.8716, 2.8299, 2.8268, 2.8263, 2.7523, 2.7507, 2.7462, 2.7426, 2.7129, 2.7121, 2.7027, 2.6921, 2.6547, 2.6516, 2.6012, 2.6402, 2.6133, 1.7998, 1.8561, 1.2593, 0.9569, 1.4384, 1.2972, 1.3709, 1.6416, 1.9166, 0.8262, 0.8179, 0.468, 0.1432, -0.0794, 0.1538, -0.6024, -0.8045, -0.2201, -0.7811, 0.0273, -0.574, -0.4378, -0.8842, -0.5741, 3.4181, 3.2718, 3.2364, 3.2223, 3.1509, 3.1287, 3.1231, 3.1128, 3.1055, 3.1054, 3.0834, 3.0734, 3.0309, 3.026, 3.025, 3.0211, 2.9996, 2.9333, 2.9332, 2.8619, 2.8278, 2.8271, 2.8228, 2.8021, 2.7931, 2.7613, 2.7584, 2.7543, 2.7365, 2.7205, 2.7139, 2.6457, 2.7167, 2.3786, 2.4781, 2.2148, 2.4158, 2.2259, 2.2511, 2.0772, 1.8239, 1.7944, 0.9531, 2.1266, 1.3132, 0.0112, -0.8697, -0.6852, 0.4397, 1.1026, 0.5869, 0.8709, -0.6675, -0.2286, -0.8602, -0.6728, -0.1873, -0.2806, -0.5806, 4.3556, 3.827, 3.8217, 3.7541, 3.7274, 3.7265, 3.3319, 3.2515, 3.2152, 3.1169, 3.1169, 3.1166, 3.0769, 2.9584, 2.958, 2.9575, 2.8097, 2.7582, 2.7578, 2.6951, 2.6449, 2.5652, 2.5293, 2.4908, 2.4908, 2.4908, 2.4907, 2.4907, 2.4906, 2.4906, 2.2941, 2.3326, 2.129, 2.3084, 2.4192, 2.3367, 2.32, 2.1604, 1.6562, 1.3851, 0.886, 1.0581, 1.7838, 1.078, 1.3524, 0.9391, 1.2143, 0.6582, 0.1854, 0.5715, 0.2761, -1.4703, -0.4411, 0.4891]}, \"token.table\": {\"Topic\": [1, 2, 3, 8, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 8, 1, 2, 3, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 1, 2, 3, 8, 1, 2, 3, 4, 5, 8, 1, 2, 3, 8, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 1, 2, 3, 7, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 7, 1, 2, 3, 7, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 6, 7, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 5, 1, 2, 3, 5, 1, 2, 3, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 7, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 1, 2, 3, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 8, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 1, 2, 3, 4, 6, 7, 1, 2, 3, 4, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 7, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 7, 1, 2, 3, 5, 7, 1, 2, 3, 5, 7, 1, 2, 3, 4, 1, 2, 3, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 7, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 6, 7, 1, 2, 3, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 1, 2, 3, 4, 5, 7, 1, 2, 3, 5, 8, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 5, 8, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 7, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 8, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 7, 1, 2, 3, 7, 1, 2, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 7, 1, 2, 3, 6, 1, 2, 3, 6, 1, 2, 3, 6, 1, 2, 3, 6, 1, 2, 3, 1, 2, 3, 4, 7, 1, 2, 3, 1, 2, 3, 4, 5, 7, 1, 2, 3, 5, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 8, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 5, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 7, 1, 2, 3, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 6, 7, 1, 2, 3, 6, 1, 2, 3, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 8, 1, 2, 3, 4, 6, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 5, 7, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 6, 1, 2, 3, 6, 1, 2, 3, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 1, 2, 3, 7, 1, 2, 3, 5, 1, 2, 3, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 1, 2, 3, 7, 1, 2, 3, 1, 2, 3, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 1, 2, 3, 6, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 7, 1, 2, 3, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 6, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 8, 1, 2, 3, 7, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 5, 1, 2, 3, 4, 6, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 6, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 1, 2, 3, 4, 6, 1, 2, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 1, 2, 3, 8, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 6, 7, 1, 2, 3, 7, 1, 2, 3, 6, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 5, 1, 2, 3, 5, 1, 2, 3, 4, 7, 1, 2, 3, 7, 1, 2, 3, 5, 6, 1, 2, 3, 5, 1, 2, 3, 4, 6, 1, 2, 3, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 7, 1, 2, 3, 8, 1, 2, 3, 8, 1, 2, 3, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 7, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 1, 2, 3, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 8, 1, 2, 3, 5, 1, 2, 3, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 6, 1, 2, 3, 4, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 5, 7, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 4, 7, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 8, 1, 2, 3, 8, 1, 2, 3, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 6, 1, 2, 3, 4, 6, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 1, 2, 3, 1, 2, 3, 7, 1, 2, 3, 4, 7, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 6, 7, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 6, 1, 2, 3, 1, 2, 3, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 6, 1, 2, 3, 1, 2, 3, 4, 8, 1, 2, 3], \"Freq\": [0.19213652948871437, 0.19213652948871437, 0.19213652948871437, 0.19213652948871437, 0.4868333875289848, 0.13079105933614518, 0.16712190915174105, 0.20345275896733694, 0.007266169963119176, 0.007266169963119176, 0.2045894483936619, 0.10229472419683094, 0.30688417259049283, 0.10229472419683094, 0.10229472419683094, 0.10229472419683094, 0.5820581185635127, 0.11265641004455086, 0.22531282008910172, 0.018776068340758477, 0.018776068340758477, 0.018776068340758477, 0.07700706503335056, 0.23102119510005167, 0.1283451083889176, 0.1283451083889176, 0.30802826013340223, 0.10267608671113408, 0.02566902167778352, 0.03993704156385677, 0.03993704156385677, 0.8386778728409922, 0.03993704156385677, 0.055245000889012436, 0.8286750133351866, 0.055245000889012436, 0.06331447418556799, 0.8230881644123837, 0.06331447418556799, 0.9248301599181018, 0.019677237445065998, 0.019677237445065998, 0.0879746253607706, 0.0879746253607706, 0.0879746253607706, 0.6158223775253941, 0.6330347798702186, 0.1808670799629196, 0.09970877485135311, 0.07652068767661983, 0.002318808717473328, 0.004637617434946656, 0.0069564261524199845, 0.6056477833819953, 0.1790785804684305, 0.12676348954506877, 0.04024237763335517, 0.02615754546168086, 0.01207271329000655, 0.008048475526671034, 0.5369220715477692, 0.25354653378644654, 0.13124761748945468, 0.03877770516733889, 0.005965800794975213, 0.02684610357738846, 0.0029829003974876063, 0.0029829003974876063, 0.07130921170176628, 0.07130921170176628, 0.07130921170176628, 0.7844013287194291, 0.22838159323970425, 0.22838159323970425, 0.22838159323970425, 0.22838159323970425, 0.1505904034104122, 0.1505904034104122, 0.1505904034104122, 0.1505904034104122, 0.1505904034104122, 0.3011808068208244, 0.22840802661437717, 0.22840802661437717, 0.22840802661437717, 0.22840802661437717, 0.9078236388675915, 0.028369488714612236, 0.028369488714612236, 0.7765878259254895, 0.08795607973189246, 0.08152026901980276, 0.03432432379781169, 0.010726351186816153, 0.0021452702373632305, 0.0021452702373632305, 0.05991276414495389, 0.8088223159568776, 0.08986914621743083, 0.10079930515268763, 0.10079930515268763, 0.10079930515268763, 0.7055951360688134, 0.11754715202180929, 0.11754715202180929, 0.11754715202180929, 0.5877357601090465, 0.11754715202180929, 0.14720192297544454, 0.7065692302821338, 0.029440384595088905, 0.05888076919017781, 0.029440384595088905, 0.28137440293608595, 0.04019634327658371, 0.36176708948925335, 0.020098171638291855, 0.28137440293608595, 0.11714181308220595, 0.058570906541102974, 0.058570906541102974, 0.7028508784932357, 0.058570906541102974, 0.058570906541102974, 0.3479856265262644, 0.1739928132631322, 0.1739928132631322, 0.1739928132631322, 0.1572400987279286, 0.1572400987279286, 0.1572400987279286, 0.4717202961837858, 0.03244486956287335, 0.7137871303832137, 0.03244486956287335, 0.1946692173772401, 0.6466509346219049, 0.13048149422637845, 0.16502071328630216, 0.026863837046607327, 0.013431918523303664, 0.01151307301997457, 0.005756536509987285, 0.0019188455033290947, 0.14226281662573406, 0.14226281662573406, 0.14226281662573406, 0.4267884498772022, 0.12391877722200274, 0.12391877722200274, 0.12391877722200274, 0.495675108888011, 0.060258130752286934, 0.7833556997797302, 0.060258130752286934, 0.061489994549939496, 0.061489994549939496, 0.7993699291492135, 0.08401694581865214, 0.08401694581865214, 0.08401694581865214, 0.6721355665492171, 0.08401694581865214, 0.18550459848153453, 0.037100919696306904, 0.1113027590889207, 0.29680735757045523, 0.14840367878522762, 0.1113027590889207, 0.1113027590889207, 0.24866463395575558, 0.24866463395575558, 0.24866463395575558, 0.1354536790516944, 0.0451512263505648, 0.0451512263505648, 0.7675708479596016, 0.07398783221206, 0.07398783221206, 0.07398783221206, 0.7398783221206, 0.6272623800955219, 0.24874197831374145, 0.07137813290742145, 0.025955684693607803, 0.010814868622336585, 0.012977842346803901, 0.0043259474489346335, 0.08463342357528685, 0.014105570595881143, 0.7899119533693439, 0.014105570595881143, 0.07052785297940571, 0.014105570595881143, 0.11652965916645355, 0.11652965916645355, 0.11652965916645355, 0.5826482958322677, 0.05613234661115591, 0.05613234661115591, 0.7858528525561828, 0.10759018092227816, 0.10759018092227816, 0.10759018092227816, 0.645541085533669, 0.36658738536890556, 0.017456542160424072, 0.017456542160424072, 0.1920219637646648, 0.3142177588876333, 0.017456542160424072, 0.06982616864169629, 0.13062570713951066, 0.13062570713951066, 0.13062570713951066, 0.5225028285580426, 0.8687860724448982, 0.03475144289779593, 0.03475144289779593, 0.03475144289779593, 0.1422634833690831, 0.1422634833690831, 0.1422634833690831, 0.42679045010724925, 0.4475138360869338, 0.2110914321164782, 0.09288023013125041, 0.10132388741590953, 0.03377462913863651, 0.10976754470056867, 0.008443657284659128, 0.06383653183575407, 0.06383653183575407, 0.06383653183575407, 0.12767306367150813, 0.6383653183575406, 0.0289899023373062, 0.0289899023373062, 0.144949511686531, 0.2029293163611434, 0.3478788280476744, 0.2319192186984496, 0.39985279831209913, 0.06356634229576962, 0.45521703192454366, 0.022555798879144055, 0.05331370644161322, 0.002050527170831278, 0.002050527170831278, 0.04904929396291836, 0.8338379973696121, 0.04904929396291836, 0.0473115624582471, 0.8516081242484478, 0.0473115624582471, 0.7779974673504066, 0.01041960893772866, 0.18407975789987302, 0.013892811916971549, 0.003473202979242887, 0.003473202979242887, 0.003473202979242887, 0.6244779112580258, 0.018734337337740773, 0.29974939740385237, 0.0031223895562901287, 0.037468674675481546, 0.006244779112580257, 0.009367168668870387, 0.10681011763195809, 0.10681011763195809, 0.10681011763195809, 0.5340505881597905, 0.0193458540283504, 0.0193458540283504, 0.9286009933608192, 0.0193458540283504, 0.4276417789215342, 0.06523349169989505, 0.19570047509968513, 0.05798532595546226, 0.02899266297773113, 0.166707812121954, 0.05073716021102948, 0.051841034087752674, 0.051841034087752674, 0.8294565454040428, 0.04150817535955659, 0.16603270143822635, 0.04150817535955659, 0.16603270143822635, 0.5396062796742356, 0.16048375293219116, 0.20060469116523894, 0.16048375293219116, 0.04012093823304779, 0.08024187646609558, 0.04012093823304779, 0.32096750586438233, 0.1103490867567359, 0.1103490867567359, 0.1103490867567359, 0.5517454337836795, 0.05492410752519941, 0.741475451590192, 0.027462053762599706, 0.05492410752519941, 0.027462053762599706, 0.08238616128779912, 0.5113828125303731, 0.10709587696971164, 0.31861023398489213, 0.050870541560613027, 0.008032190772728372, 0.002677396924242791, 0.002677396924242791, 0.2241879163750352, 0.04719745607895478, 0.12979300421712564, 0.15339173225660302, 0.4365764687303317, 0.6447259942078528, 0.10745433236797547, 0.053727166183987735, 0.053727166183987735, 0.053727166183987735, 0.053727166183987735, 0.2414888825161455, 0.2414888825161455, 0.2414888825161455, 0.6061143810325755, 0.2532590606192452, 0.06260336329913926, 0.05122093360838667, 0.01991925195881704, 0.008536822268064445, 0.0028456074226881484, 0.3364810746423162, 0.40377728957077946, 0.10094432239269487, 0.06729621492846324, 0.03364810746423162, 0.03364810746423162, 0.03364810746423162, 0.10549013567606151, 0.10549013567606151, 0.10549013567606151, 0.632940814056369, 0.22402851593773393, 0.11201425796886696, 0.6098554044971646, 0.02489205732641488, 0.01244602866320744, 0.01244602866320744, 0.01244602866320744, 0.6015483921620061, 0.33300000280396763, 0.021483871148643075, 0.026854838935803843, 0.010741935574321538, 0.005370967787160769, 0.3899200669151833, 0.5614848963578639, 0.015596802676607333, 0.015596802676607333, 0.015596802676607333, 0.06627983238483419, 0.7953579886180103, 0.06627983238483419, 0.4850364317041437, 0.07732464853254464, 0.23900345910059254, 0.007029513502958605, 0.07732464853254464, 0.10544270254437907, 0.007029513502958605, 0.05702135864185824, 0.02851067932092912, 0.05702135864185824, 0.08553203796278736, 0.6557456243813697, 0.05702135864185824, 0.05702135864185824, 0.02851067932092912, 0.05011588191211896, 0.05011588191211896, 0.8519699925060223, 0.6933220621552049, 0.04220221247901247, 0.03617332498201069, 0.16880884991604989, 0.04823109997601425, 0.018086662491005344, 0.02086617411321073, 0.02086617411321073, 0.9389778350944828, 0.02086617411321073, 0.08427267249864821, 0.08427267249864821, 0.08427267249864821, 0.08427267249864821, 0.6741813799891857, 0.6511131607329093, 0.1014721808934404, 0.1014721808934404, 0.016912030148906736, 0.03382406029781347, 0.008456015074453368, 0.0761041356700803, 0.16481937128842689, 0.16481937128842689, 0.16481937128842689, 0.32963874257685377, 0.0662857025671232, 0.7954284308054783, 0.0662857025671232, 0.7003156322309562, 0.09790596832176196, 0.12209450167184432, 0.039162387328704786, 0.014973853978622418, 0.011518349214324937, 0.013822019057189924, 0.0011518349214324937, 0.10545247511295029, 0.10545247511295029, 0.10545247511295029, 0.10545247511295029, 0.5272623755647515, 0.5755918390359925, 0.03385834347270544, 0.03385834347270544, 0.03385834347270544, 0.304725091254349, 0.08667686545764726, 0.08667686545764726, 0.08667686545764726, 0.5200611927458836, 0.17335373091529452, 0.10066653080879746, 0.10066653080879746, 0.10066653080879746, 0.7046657156615822, 0.1547149093367029, 0.07735745466835145, 0.07735745466835145, 0.696217092015163, 0.3750547856735007, 0.07292731943651402, 0.48444576482827173, 0.015627282736395864, 0.015627282736395864, 0.005209094245465287, 0.020836376981861148, 0.04391188625934471, 0.04391188625934471, 0.4391188625934471, 0.3512950900747577, 0.061368426867122954, 0.061368426867122954, 0.7977895492725984, 0.5204440780747993, 0.3035923788769663, 0.10408881561495988, 0.04337033983956661, 0.013878508748661316, 0.01214369515507865, 0.003469627187165329, 0.13257157254102794, 0.13257157254102794, 0.06628578627051397, 0.1988573588115419, 0.06628578627051397, 0.3977147176230838, 0.3465122966799373, 0.3465122966799373, 0.0630022357599886, 0.17325614833996866, 0.04725167681999145, 0.007875279469998575, 0.01575055893999715, 0.007875279469998575, 0.10081439892826216, 0.10081439892826216, 0.10081439892826216, 0.7057007924978351, 0.03146696172257514, 0.03146696172257514, 0.912541889954679, 0.16509545636544493, 0.1589808098333914, 0.6603818254617797, 0.006114646532053516, 0.006114646532053516, 0.006114646532053516, 0.057260484087814534, 0.057260484087814534, 0.057260484087814534, 0.11452096817562907, 0.6871258090537744, 0.45381269489671544, 0.21908199063979367, 0.15648713617128118, 0.031297427234256235, 0.015648713617128118, 0.046946140851384356, 0.06259485446851247, 0.13032245521302283, 0.026064491042604568, 0.8079992223207416, 0.026064491042604568, 0.026064491042604568, 0.3212012679448571, 0.24982320840155553, 0.15465246234382007, 0.24982320840155553, 0.01189634325721693, 0.6233812752271373, 0.16005735445021094, 0.06739257029482565, 0.033696285147412824, 0.005616047524568804, 0.09828083167995408, 0.011232095049137608, 0.4902710922577746, 0.18521352374182595, 0.01089491316128388, 0.29416265535466474, 0.37333156962115444, 0.5882800491000009, 0.01131307786730771, 0.01131307786730771, 0.02262615573461542, 0.6112110145963037, 0.11218430014742284, 0.18955278300771444, 0.046421089716174965, 0.03288160521562394, 0.0038684241430145803, 0.005802636214521871, 0.6945784119075814, 0.057284817476913934, 0.1754347535230489, 0.017901505461535603, 0.003580301092307121, 0.010740903276921362, 0.03938331201537833, 0.8923263206140151, 0.05318501248692805, 0.03545667499128537, 0.01181889166376179, 0.005909445831880895, 0.4154250865602523, 0.008478062991025557, 0.5595521574076867, 0.008478062991025557, 0.008478062991025557, 0.008478062991025557, 0.04895124963999156, 0.09790249927998312, 0.8321712438798565, 0.13857635522598688, 0.06928817761299344, 0.06928817761299344, 0.6928817761299344, 0.06928817761299344, 0.8364817340966353, 0.007581405444984609, 0.13646529800972299, 0.007581405444984609, 0.0012635675741641016, 0.007581405444984609, 0.0012635675741641016, 0.02219573306944035, 0.02219573306944035, 0.9322207889164948, 0.16223459412222174, 0.20279324265277715, 0.08111729706111087, 0.48670378236666517, 0.040558648530555436, 0.040558648530555436, 0.08681280744056971, 0.08681280744056971, 0.26043842232170916, 0.26043842232170916, 0.17362561488113942, 0.33333061675098097, 0.14285597860756327, 0.1904746381434177, 0.12244798166362565, 0.13605331295958406, 0.05442132518383363, 0.02040799694393761, 0.6065073605877092, 0.1370071723641657, 0.15705700246623874, 0.050124575255182574, 0.018379010926900276, 0.005012457525518258, 0.026733106802764042, 0.17650550447308358, 0.04073203949378852, 0.21723754396687212, 0.027154692995859014, 0.35301100894616716, 0.013577346497929507, 0.1629281579751541, 0.6856506371111843, 0.15096894762081123, 0.11532350165478635, 0.014677536574245536, 0.014677536574245536, 0.008387163756711735, 0.008387163756711735, 0.05003422545763535, 0.05003422545763535, 0.8505818327798009, 0.03401704687549595, 0.3288314531297942, 0.5896288125085966, 0.022678031250330636, 0.011339015625165318, 0.011339015625165318, 0.011339015625165318, 0.1611753345394132, 0.1611753345394132, 0.1611753345394132, 0.1611753345394132, 0.3223506690788264, 0.04918143660156109, 0.8360844222265386, 0.04918143660156109, 0.6870704856211446, 0.15415042946628243, 0.10570315163402225, 0.024223638916130098, 0.011010744961877317, 0.008808595969501854, 0.00660644697712639, 0.03930384220758879, 0.03930384220758879, 0.8253806863593646, 0.03930384220758879, 0.03863038737360978, 0.03863038737360978, 0.8884989095930249, 0.27325759608546496, 0.12943780867206237, 0.12943780867206237, 0.043145936224020784, 0.12943780867206237, 0.14381978741340262, 0.15820176615474288, 0.1653076898475677, 0.1653076898475677, 0.1653076898475677, 0.49592306954270304, 0.797247536861821, 0.09953630712320455, 0.05551063281871023, 0.02009867739987784, 0.009570798761846591, 0.015313278018954546, 0.0028712396285539774, 0.6157773883419071, 0.07509480345633013, 0.1201516855301282, 0.04505688207379808, 0.0600758427650641, 0.03003792138253205, 0.015018960691266025, 0.0600758427650641, 0.18376330401271504, 0.18376330401271504, 0.18376330401271504, 0.3675266080254301, 0.35940170372035274, 0.19027149020489265, 0.1479889368260276, 0.06342383006829755, 0.021141276689432515, 0.21141276689432514, 0.4842678021523068, 0.011811409808592849, 0.011811409808592849, 0.472456392343714, 0.06633702269778813, 0.7960442723734575, 0.06633702269778813, 0.895725495687326, 0.021326797516364904, 0.021326797516364904, 0.021326797516364904, 0.15526883404258868, 0.15526883404258868, 0.15526883404258868, 0.46580650212776603, 0.053016984103225244, 0.8482717456516039, 0.053016984103225244, 0.5277125394067851, 0.37191169443906763, 0.055284170794996534, 0.015077501125908147, 0.005025833708636049, 0.020103334834544195, 0.6758028671388585, 0.14710364133841533, 0.1223436224992761, 0.032042377321238984, 0.013108245267779583, 0.004369415089259861, 0.0029129433928399076, 0.12384232804901711, 0.12384232804901711, 0.12384232804901711, 0.49536931219606845, 0.07647933181406656, 0.07647933181406656, 0.07647933181406656, 0.6883139863265991, 0.11370849861168758, 0.11370849861168758, 0.11370849861168758, 0.568542493058438, 0.12293816729617747, 0.12293816729617747, 0.12293816729617747, 0.4917526691847099, 0.2669605515588096, 0.1334802757794048, 0.1334802757794048, 0.40044082733821446, 0.891767453366764, 0.03302842419876904, 0.03302842419876904, 0.0835817727446398, 0.0417908863723199, 0.2507453182339194, 0.5014906364678388, 0.0835817727446398, 0.24867674279544286, 0.24867674279544286, 0.24867674279544286, 0.17510820123536502, 0.4085858028825184, 0.3996058951268587, 0.008979907755659745, 0.004489953877829873, 0.004489953877829873, 0.1232736217672379, 0.1232736217672379, 0.1232736217672379, 0.6163681088361895, 0.11693661539782452, 0.11693661539782452, 0.11693661539782452, 0.5846830769891226, 0.9325278172829109, 0.022203043268640733, 0.022203043268640733, 0.40827145127414205, 0.10206786281853551, 0.21341462225693789, 0.25053020873640536, 0.009278896619866864, 0.009278896619866864, 0.009278896619866864, 0.23474325640916252, 0.23474325640916252, 0.23474325640916252, 0.23474325640916252, 0.24150730669707532, 0.24150730669707532, 0.24150730669707532, 0.06641158089847547, 0.7969389707817057, 0.06641158089847547, 0.07132235239054167, 0.07132235239054167, 0.07132235239054167, 0.7845458762959584, 0.41909198167539924, 0.027939465445026616, 0.1676367926701597, 0.027939465445026616, 0.05587893089005323, 0.027939465445026616, 0.25145518900523955, 0.027939465445026616, 0.9334003081031891, 0.02333500770257973, 0.02333500770257973, 0.02333500770257973, 0.3104347609038901, 0.009130434144232062, 0.5386956145096916, 0.10043477558655267, 0.009130434144232062, 0.018260868288464124, 0.009130434144232062, 0.1651265538126073, 0.1651265538126073, 0.1651265538126073, 0.49537966143782186, 0.6073921134547291, 0.007787078377624731, 0.3523652965875191, 0.015574156755249462, 0.007787078377624731, 0.0038935391888123656, 0.0038935391888123656, 0.30522616465888786, 0.15261308232944393, 0.07630654116472196, 0.07630654116472196, 0.30522616465888786, 0.07630654116472196, 0.8589029617149343, 0.05205472495242026, 0.02602736247621013, 0.02602736247621013, 0.013013681238105064, 0.013013681238105064, 0.013013681238105064, 0.3791194133155236, 0.12062890423675753, 0.3274213114997704, 0.10339620363150645, 0.03446540121050215, 0.017232700605251075, 0.03446540121050215, 0.24867111087824503, 0.24867111087824503, 0.24867111087824503, 0.10623835614934227, 0.10623835614934227, 0.10623835614934227, 0.6374301368960535, 0.08659761552589211, 0.08659761552589211, 0.17319523105178422, 0.6061833086812448, 0.5982483841077776, 0.05122616133032958, 0.17014403584716611, 0.053055667092127064, 0.08415726504268431, 0.02561308066516479, 0.01463604609437988, 0.10540326478785884, 0.10540326478785884, 0.10540326478785884, 0.2108065295757177, 0.4216130591514354, 0.2373621071766472, 0.542541959260908, 0.10172661736142023, 0.03390887245380675, 0.05651478742301124, 0.01130295748460225, 0.01130295748460225, 0.15648893876070052, 0.15648893876070052, 0.15648893876070052, 0.4694668162821016, 0.05151416130528198, 0.7727124195792296, 0.10302832261056397, 0.05151416130528198, 0.20912138148957188, 0.10456069074478594, 0.10456069074478594, 0.10456069074478594, 0.5228034537239297, 0.694888123947786, 0.10922990577105667, 0.1533866761891434, 0.0023240405483203547, 0.0023240405483203547, 0.03253656767648497, 0.004648081096640709, 0.1264276195697667, 0.1264276195697667, 0.1264276195697667, 0.1264276195697667, 0.1264276195697667, 0.37928285870930006, 0.15411186389160744, 0.15411186389160744, 0.15411186389160744, 0.4623355916748223, 0.141194524790534, 0.141194524790534, 0.141194524790534, 0.42358357437160193, 0.3162545008554273, 0.05270908347590454, 0.6017620363499102, 0.0043924236229920454, 0.013177270868976135, 0.013177270868976135, 0.10510835302830196, 0.10510835302830196, 0.10510835302830196, 0.6306501181698118, 0.05527959623098916, 0.8291939434648373, 0.05527959623098916, 0.1259878112245732, 0.1259878112245732, 0.5039512448982928, 0.1259878112245732, 0.15629856739362102, 0.039074641848405256, 0.039074641848405256, 0.31259713478724205, 0.39074641848405256, 0.03898914191344046, 0.8577611220956901, 0.03898914191344046, 0.5484357114939066, 0.19857155071331098, 0.1347449808411753, 0.06619051690443699, 0.026003417355314532, 0.014183682193807928, 0.014183682193807928, 0.8889783995584135, 0.019325617381704643, 0.05797685214511392, 0.009662808690852322, 0.019325617381704643, 0.7991010881074769, 0.038313065868166706, 0.11493919760450011, 0.02189318049609526, 0.016419885372071445, 0.005473295124023815, 0.6201028761409235, 0.10279780299662368, 0.20891166415442877, 0.040898050654570715, 0.017685643526300848, 0.006632116322362818, 0.003316058161181409, 0.5918415107834393, 0.033249523077721305, 0.3092205646228081, 0.023274666154404915, 0.026599618462177045, 0.009974856923316391, 0.006649904615544261, 0.10067756305995376, 0.10067756305995376, 0.10067756305995376, 0.7047429414196763, 0.8261056894120224, 0.04931974265146403, 0.09863948530292806, 0.012329935662866007, 0.0061649678314330035, 0.7952523870649539, 0.11940050004091377, 0.05181531133850975, 0.00901135849365387, 0.013517037740480804, 0.006758518870240402, 0.006758518870240402, 0.11124016128833847, 0.11124016128833847, 0.11124016128833847, 0.6674409677300308, 0.5288748148509941, 0.19324272081094013, 0.19324272081094013, 0.005085334758182635, 0.02034133903273054, 0.01017066951636527, 0.04576801282364371, 0.6160574222077779, 0.03300307618970239, 0.22002050793134925, 0.044004101586269856, 0.044004101586269856, 0.011001025396567464, 0.022002050793134928, 0.6335489175503739, 0.2939666977433735, 0.040547130723223926, 0.025341956702014955, 0.0025341956702014954, 0.0025341956702014954, 0.029847989711067998, 0.029847989711067998, 0.029847989711067998, 0.8954396913320399, 0.8981152115732175, 0.03096949005424888, 0.03096949005424888, 0.23311153463698725, 0.5889133506618626, 0.07361416883273282, 0.012269028138788803, 0.04907611255515521, 0.03680708441636641, 0.0501159498461424, 0.0501159498461424, 0.8519711473844208, 0.6569201567914343, 0.10620864810400436, 0.110142301737486, 0.03146922906785314, 0.019668268167408215, 0.003933653633481643, 0.06687211176918793, 0.0308069876784027, 0.0308069876784027, 0.8934026426736783, 0.0308069876784027, 0.5942404509538652, 0.12147456732206084, 0.17072101353370714, 0.0032830964141097522, 0.09849289242329257, 0.0032830964141097522, 0.0032830964141097522, 0.0032830964141097522, 0.5070881059145615, 0.45410875156527897, 0.007568479192754649, 0.015136958385509299, 0.07967037987676527, 0.7967037987676527, 0.039835189938382635, 0.6234383797094101, 0.26772278768301994, 0.0730153057317327, 0.020594060591001533, 0.0037443746529093698, 0.005616561979364054, 0.0018721873264546849, 0.04735264175040455, 0.8523475515072819, 0.04735264175040455, 0.9346400118141911, 0.01947166691279565, 0.01947166691279565, 0.01947166691279565, 0.9376136587852717, 0.02083585908411715, 0.02083585908411715, 0.0365659473539293, 0.0365659473539293, 0.8775827364943032, 0.935175357280372, 0.02174826412279935, 0.02174826412279935, 0.1348985267954353, 0.1348985267954353, 0.1348985267954353, 0.5395941071817412, 0.09343242090245521, 0.09343242090245521, 0.09343242090245521, 0.6540269463171865, 0.12389536945532813, 0.12389536945532813, 0.12389536945532813, 0.4955814778213125, 0.6486378933691013, 0.23555186467607792, 0.08934725901506403, 0.010443186118643848, 0.006962124079095898, 0.006962124079095898, 0.0023207080263652996, 0.8781527302648561, 0.036589697094369, 0.036589697094369, 0.13651090670632948, 0.13651090670632948, 0.13651090670632948, 0.40953272011898845, 0.07755594348101758, 0.07755594348101758, 0.07755594348101758, 0.6980034913291582, 0.052223316248557104, 0.052223316248557104, 0.052223316248557104, 0.8355730599769137, 0.29793208493012896, 0.09931069497670965, 0.09931069497670965, 0.09931069497670965, 0.3972427799068386, 0.21338886479563846, 0.6401665943869154, 0.09699493854347203, 0.019398987708694405, 0.019398987708694405, 0.8294236015509955, 0.013823726692516592, 0.11404574521326188, 0.03801524840442063, 0.003455931673129148, 0.11058727888937307, 0.11058727888937307, 0.11058727888937307, 0.5529363944468654, 0.037639157494281414, 0.037639157494281414, 0.8657006223684724, 0.11145041880997054, 0.11145041880997054, 0.11145041880997054, 0.5572520940498528, 0.627000499374167, 0.09226943665489033, 0.21637452689246212, 0.016187620465770235, 0.03345441562925849, 0.003237524093154047, 0.010791746977180156, 0.0005395873488590078, 0.051810466364428015, 0.051810466364428015, 0.8289674618308482, 0.2103029645622888, 0.1051514822811444, 0.1051514822811444, 0.4206059291245776, 0.04361718546123362, 0.04361718546123362, 0.8723437092246723, 0.09127056624147918, 0.09127056624147918, 0.09127056624147918, 0.7301645299318335, 0.13366617424648217, 0.15037444602729244, 0.434415066301067, 0.03341654356162054, 0.2506240767121541, 0.09441633255990396, 0.09441633255990396, 0.09441633255990396, 0.6609143279193277, 0.16503111843058801, 0.16503111843058801, 0.16503111843058801, 0.33006223686117603, 0.13341133530511806, 0.04447044510170602, 0.7411740850284337, 0.014823481700568674, 0.029646963401137347, 0.014823481700568674, 0.014823481700568674, 0.6145073409562971, 0.13005446369445442, 0.1560653564333453, 0.058524508662504485, 0.016256807961806802, 0.02275953114652952, 0.00325136159236136, 0.00162568079618068, 0.5141828521545455, 0.15984959134338203, 0.09857391466175225, 0.06393983653735281, 0.06926815624879888, 0.07193231610452192, 0.018649118990061237, 0.15860816200349473, 0.15860816200349473, 0.15860816200349473, 0.15860816200349473, 0.15860816200349473, 0.15860816200349473, 0.31910622993513754, 0.024546633071933655, 0.01636442204795577, 0.057275477167845194, 0.36001728505502695, 0.11455095433569039, 0.09818653228773462, 0.028390074777873982, 0.8800923181140935, 0.028390074777873982, 0.028390074777873982, 0.2983416201682475, 0.18766650300905893, 0.49082008479292333, 0.00962392323123379, 0.004811961615616895, 0.004811961615616895, 0.5400959664914651, 0.26804762781428265, 0.04400781949189715, 0.03200568690319793, 0.02800497604029819, 0.06401137380639586, 0.02800497604029819, 0.6024827488782863, 0.1258125740304657, 0.18251683274842206, 0.053160242548084095, 0.012404056594552956, 0.010632048509616819, 0.012404056594552956, 0.07594938101928347, 0.07594938101928347, 0.07594938101928347, 0.6835444291735512, 0.18124058201176482, 0.020713209372773125, 0.7715670491357989, 0.015534907029579843, 0.005178302343193281, 0.005178302343193281, 0.619497630714087, 0.15127267726739335, 0.14406921644513654, 0.007203460822256826, 0.007203460822256826, 0.007203460822256826, 0.06483114740031144, 0.8540494816955752, 0.06486451759713228, 0.037837635264993834, 0.027026882332138454, 0.005405376466427691, 0.005405376466427691, 0.24867296762254062, 0.24867296762254062, 0.24867296762254062, 0.10648606672679287, 0.10648606672679287, 0.10648606672679287, 0.5324303336339643, 0.033002471589991665, 0.033002471589991665, 0.8910667329297749, 0.7248051635586292, 0.14055157164064672, 0.03582687120251779, 0.04133869754136668, 0.0027559131694244454, 0.04409461071079113, 0.011023652677697782, 0.6879408038481828, 0.19539147091546022, 0.061059834661081315, 0.024423933864432527, 0.004070655644072088, 0.008141311288144175, 0.004070655644072088, 0.01628262257628835, 0.6734112789149396, 0.11814232963419992, 0.1299565625976199, 0.03544269889025997, 0.011814232963419992, 0.011814232963419992, 0.011814232963419992, 0.011814232963419992, 0.08289594978647917, 0.08289594978647917, 0.08289594978647917, 0.6631675982918334, 0.06175477051538428, 0.06175477051538428, 0.06175477051538428, 0.7410572461846113, 0.6424540129834373, 0.15656442333209816, 0.09717791793026782, 0.06748466522935265, 0.010797546436696424, 0.002699386609174106, 0.021595092873392847, 0.10640610383620669, 0.10640610383620669, 0.10640610383620669, 0.5320305191810334, 0.5618598008579915, 0.1068567719423174, 0.2309485071011376, 0.013787970573202244, 0.05859887493610954, 0.013787970573202244, 0.010340977929901683, 0.2269979831960056, 0.07566599439866853, 0.15133198879733706, 0.025221998132889507, 0.07566599439866853, 0.025221998132889507, 0.4035519701262321, 0.14789319933272488, 0.14789319933272488, 0.14789319933272488, 0.44367959799817464, 0.7304586834134656, 0.1168733893461545, 0.09414800808440224, 0.029218347336538626, 0.021102139743055675, 0.004869724556089771, 0.0032464830373931807, 0.23473897316532005, 0.23473897316532005, 0.23473897316532005, 0.23473897316532005, 0.16569127530207414, 0.16569127530207414, 0.16569127530207414, 0.3313825506041483, 0.06158379702582509, 0.030791898512912544, 0.8313812598486386, 0.030791898512912544, 0.7024527664598849, 0.05108747392435527, 0.17242022449469901, 0.019157802721633223, 0.03831560544326645, 0.012771868481088817, 0.006385934240544408, 0.22837907341062225, 0.22837907341062225, 0.22837907341062225, 0.22837907341062225, 0.6695191662845265, 0.12340157182499116, 0.11815044110903408, 0.03150678429574242, 0.013127826789892676, 0.028881218937763888, 0.013127826789892676, 0.058703198556548326, 0.058703198556548326, 0.8218447797916766, 0.10757726503365773, 0.12102442316286495, 0.6589107483311536, 0.0941301069044505, 0.013447158129207217, 0.18047273319611576, 0.22212028701060402, 0.15270769731979025, 0.12494266144346476, 0.1943552511342785, 0.055530071752651004, 0.0832951076289765, 0.09000624741831244, 0.09000624741831244, 0.09000624741831244, 0.7200499793464995, 0.3456726079019438, 0.08641815197548595, 0.08641815197548595, 0.08641815197548595, 0.3456726079019438, 0.1384380152442091, 0.1384380152442091, 0.1384380152442091, 0.5537520609768364, 0.0613543323760708, 0.0613543323760708, 0.7976063208889204, 0.2280738034211675, 0.11403690171058375, 0.11403690171058375, 0.3421107051317513, 0.8904928997123086, 0.030706651714217537, 0.030706651714217537, 0.030706651714217537, 0.030706651714217537, 0.8975335169124885, 0.028952694093951244, 0.028952694093951244, 0.028952694093951244, 0.028952694093951244, 0.04561862674666829, 0.8211352814400293, 0.04561862674666829, 0.22811317485291796, 0.01520754499019453, 0.01520754499019453, 0.7299621595293375, 0.6387347435171402, 0.10251298352744226, 0.20108315999613674, 0.021685438823112788, 0.00788561411749556, 0.00394280705874778, 0.021685438823112788, 0.2486801862369048, 0.2486801862369048, 0.2486801862369048, 0.9321091556754645, 0.040234927583113575, 0.013411642527704524, 0.006705821263852262, 0.006705821263852262, 0.8655345726506387, 0.03934248057502903, 0.03934248057502903, 0.5545569573341299, 0.051347866419826846, 0.02053914656793074, 0.061617439703792215, 0.26700890538309957, 0.051347866419826846, 0.41823490694126264, 0.009957973974791968, 0.298739219243759, 0.0896217657731277, 0.16928555757146344, 0.009957973974791968, 0.9443435164924285, 0.012264201512888682, 0.012264201512888682, 0.012264201512888682, 0.012264201512888682, 0.23471342472725706, 0.23471342472725706, 0.23471342472725706, 0.23471342472725706, 0.08199054146572833, 0.08199054146572833, 0.08199054146572833, 0.08199054146572833, 0.6559243317258266, 0.12223742039342204, 0.7741703291583396, 0.04074580679780735, 0.5728747751496157, 0.20537020241212642, 0.15132541230367208, 0.051882998504116144, 0.00864716641735269, 0.006485374813014518, 0.004323583208676345, 0.6849827180947701, 0.19059384230292928, 0.09587447824935232, 0.016171598740854606, 0.003465342587325987, 0.003465342587325987, 0.004620456783101316, 0.16366190499923922, 0.12274642874942943, 0.040915476249809804, 0.3682392862482883, 0.040915476249809804, 0.08183095249961961, 0.20457738124904903, 0.23106606395999704, 0.2426193671579969, 0.023106606395999704, 0.47368543111799394, 0.011553303197999852, 0.011553303197999852, 0.04800944051776095, 0.04800944051776095, 0.04800944051776095, 0.8161604888019361, 0.22323660539084422, 0.11161830269542211, 0.11161830269542211, 0.5580915134771105, 0.04507740784807632, 0.04507740784807632, 0.8564707491134501, 0.1752459354520709, 0.08762296772603545, 0.08762296772603545, 0.6133607740822482, 0.015939187368090055, 0.06375674947236022, 0.892594492613043, 0.015939187368090055, 0.3828479022496402, 0.41287518870059237, 0.172656897092975, 0.007506821612738043, 0.007506821612738043, 0.007506821612738043, 0.015013643225476086, 0.03762964219494185, 0.03762964219494185, 0.8654817704836626, 0.03762964219494185, 0.5045024419014408, 0.2673431743409344, 0.07330377360961104, 0.05605582687793786, 0.021559933414591486, 0.06467980024377445, 0.01293596004875489, 0.11689915480053076, 0.11689915480053076, 0.11689915480053076, 0.5844957740026537, 0.12313102278788403, 0.12313102278788403, 0.12313102278788403, 0.6156551139394202, 0.2151550445569086, 0.1075775222784543, 0.05378876113922715, 0.5916763725314986, 0.05378876113922715, 0.21019484109753483, 0.07006494703251161, 0.07006494703251161, 0.5605195762600929, 0.04545967596502939, 0.04545967596502939, 0.04545967596502939, 0.31821773175520573, 0.5000564356153233, 0.09297089330034689, 0.09297089330034689, 0.09297089330034689, 0.6507962531024283, 0.1798110715443285, 0.05993702384810949, 0.05993702384810949, 0.5394332146329854, 0.11987404769621898, 0.8943138306147412, 0.031939779664812186, 0.031939779664812186, 0.5150240309592488, 0.044398623358555926, 0.2308728414644908, 0.1154364207322454, 0.01775944934342237, 0.044398623358555926, 0.01775944934342237, 0.8817217658449327, 0.06429221209285968, 0.009184601727551383, 0.004592300863775691, 0.004592300863775691, 0.022961504318878456, 0.009184601727551383, 0.009688225343220962, 0.6006699712796997, 0.009688225343220962, 0.3681525630423965, 0.9078630778893236, 0.02928590573836528, 0.02928590573836528, 0.02928590573836528, 0.8956362536369626, 0.02714049253445341, 0.02714049253445341, 0.5537161414841368, 0.07637464020470852, 0.3245922208700112, 0.03054985608188341, 0.0076374640204708525, 0.0076374640204708525, 0.2868390286353262, 0.03309681099638379, 0.16548405498191895, 0.05516135166063965, 0.2206454066425586, 0.17651632531404687, 0.06619362199276758, 0.6111271621852657, 0.16513436084580585, 0.14042922024682702, 0.04550946952443468, 0.01300270557840991, 0.015603246694091891, 0.009101893904886936, 0.001300270557840991, 0.06641657009899066, 0.7969988411878879, 0.06641657009899066, 0.9561210193442418, 0.018933089491965184, 0.009466544745982592, 0.009466544745982592, 0.6073569471558404, 0.048980398964180674, 0.20571767564955884, 0.06857255854985295, 0.03918431917134454, 0.009796079792836134, 0.01959215958567227, 0.009796079792836134, 0.8923764326792651, 0.014629121847201068, 0.029258243694402136, 0.014629121847201068, 0.014629121847201068, 0.043887365541603204, 0.06212809323548979, 0.06212809323548979, 0.6212809323548979, 0.18638427970646937, 0.12252238408124548, 0.12252238408124548, 0.12252238408124548, 0.4900895363249819, 0.07480065378077312, 0.07480065378077312, 0.07480065378077312, 0.7480065378077313, 0.0929651226193971, 0.0929651226193971, 0.0929651226193971, 0.6507558583357798, 0.5168037616387481, 0.10932387265435056, 0.13913947428735526, 0.18883214367569642, 0.03975413551067293, 0.61896658845214, 0.24727559689419665, 0.08553558383132588, 0.023327886499452513, 0.007775962166484171, 0.012441539466374673, 0.004665577299890503, 0.035449027697987676, 0.779878609355729, 0.10634708309396304, 0.035449027697987676, 0.09477137508056087, 0.09477137508056087, 0.09477137508056087, 0.6633996255639261, 0.06878035720903532, 0.06878035720903532, 0.06878035720903532, 0.7565839292993886, 0.14208775063175774, 0.14208775063175774, 0.14208775063175774, 0.568351002527031, 0.6184435779751019, 0.12212961413794028, 0.15331164327954205, 0.06236405828320355, 0.023386521856201332, 0.007795507285400444, 0.010394009713867258, 0.32039700852202424, 0.11650800309891791, 0.02912700077472948, 0.46603201239567166, 0.02912700077472948, 0.3400976900372125, 0.034009769003721255, 0.13603907601488502, 0.06801953800744251, 0.06801953800744251, 0.3741074590409338, 0.8284431741955484, 0.08847451374903914, 0.05630196329484309, 0.024129412840647037, 0.008043137613549012, 0.15352246838594258, 0.021931781197991797, 0.7676123419297128, 0.021931781197991797, 0.09638819001522186, 0.04819409500761093, 0.24097047503805466, 0.5783291400913312, 0.599198803338352, 0.143457815689766, 0.18457072628378432, 0.042862396151210576, 0.01224639890034588, 0.013121141678942013, 0.005248456671576806, 0.10087269696191653, 0.033624232320638846, 0.48755136864926324, 0.2858059747254302, 0.016812116160319423, 0.050436348480958265, 0.016812116160319423, 0.5624623696660571, 0.16728974460793736, 0.15938629210677496, 0.061910377925772093, 0.026344841670541318, 0.009220694584689462, 0.010537936668216527, 0.0013172420835270658, 0.21159389740982718, 0.10579694870491359, 0.03526564956830453, 0.6347816922294816, 0.4877232621176131, 0.16084490559197878, 0.24386163105880654, 0.04150836273341388, 0.025942726708383674, 0.015565636025030204, 0.015565636025030204, 0.01037709068335347, 0.5677615832484536, 0.11355231664969073, 0.11355231664969073, 0.11355231664969073, 0.1306390175808007, 0.1306390175808007, 0.1306390175808007, 0.5225560703232028, 0.11703613030068823, 0.23407226060137645, 0.11703613030068823, 0.4681445212027529, 0.5652664660157033, 0.13932624162358884, 0.17515298946965452, 0.01990374880336983, 0.06767274593145743, 0.015922999042695864, 0.015922999042695864, 0.03581960110521478, 0.8954900276303694, 0.03581960110521478, 0.519520519839699, 0.2344177955374252, 0.11404108972090955, 0.06969177705166694, 0.03484588852583347, 0.01900684828681826, 0.006335616095606086, 0.0800259759924541, 0.0800259759924541, 0.0800259759924541, 0.7202337839320869, 0.7249331736974004, 0.11152818056883083, 0.07435212037922055, 0.07435212037922055, 0.0030980050158008563, 0.006196010031601713, 0.006196010031601713, 0.775698031043362, 0.12770638315957789, 0.04729866042947329, 0.028379196257683974, 0.004729866042947329, 0.004729866042947329, 0.009459732085894658, 0.14924304577479047, 0.14924304577479047, 0.14924304577479047, 0.4477291373243714, 0.06185434465863928, 0.06185434465863928, 0.06185434465863928, 0.37112606795183567, 0.06185434465863928, 0.43298041261047493, 0.30536612792315204, 0.012214645116926083, 0.08550251581848257, 0.5374443851447477, 0.012214645116926083, 0.012214645116926083, 0.03664393535077825, 0.6140188408670993, 0.1264156437079322, 0.19865315439817918, 0.03386133313605327, 0.009029688836280872, 0.015801955463491526, 0.002257422209070218, 0.002257422209070218, 0.4365203849297955, 0.4579886005820805, 0.05009250318866506, 0.04293643130457005, 0.007156071884095008, 0.007156071884095008, 0.06024251604492058, 0.7831527085839675, 0.06024251604492058, 0.08137794354494723, 0.08137794354494723, 0.08137794354494723, 0.6510235483595779, 0.11737930874584854, 0.11737930874584854, 0.11737930874584854, 0.5868965437292426, 0.5860453605258988, 0.02548023306634343, 0.02548023306634343, 0.10192093226537371, 0.07644069919903028, 0.17836163146440398, 0.09961194629207086, 0.09961194629207086, 0.09961194629207086, 0.5976716777524251, 0.039367198611857716, 0.31493758889486173, 0.019683599305928858, 0.019683599305928858, 0.3346211882007906, 0.019683599305928858, 0.2362031916711463, 0.05976987728234887, 0.05976987728234887, 0.05976987728234887, 0.5976987728234887, 0.17930963184704662, 0.9089159275765939, 0.02931986863150303, 0.02931986863150303, 0.02931986863150303, 0.24867260251143633, 0.24867260251143633, 0.24867260251143633, 0.25917927706068816, 0.06479481926517204, 0.06479481926517204, 0.12958963853034408, 0.3887689155910322, 0.07918196644940068, 0.07918196644940068, 0.07918196644940068, 0.7126376980446061, 0.6570049716328671, 0.06882909226630035, 0.07717201254100343, 0.04797179157954267, 0.143915374738628, 0.0020857300686757682, 0.0020857300686757682, 0.14341245830214439, 0.02868249166042888, 0.02868249166042888, 0.7744272748315797, 0.07299096591943112, 0.07299096591943112, 0.14598193183886224, 0.583927727355449, 0.11237238193805474, 0.11237238193805474, 0.11237238193805474, 0.6742342916283284, 0.255246621146181, 0.024309202013922, 0.23093741913225901, 0.158009813090493, 0.24309202013922002, 0.07292760604176601, 0.012154601006961, 0.3049024315458851, 0.33539267470047357, 0.21343170208211956, 0.03049024315458851, 0.03049024315458851, 0.09147072946376553, 0.19203122149751434, 0.19203122149751434, 0.19203122149751434, 0.19203122149751434, 0.17233305881230443, 0.7631892604544911, 0.024619008401757778, 0.10738248414712372, 0.021476496829424745, 0.6657714017121671, 0.04295299365884949, 0.021476496829424745, 0.10738248414712372, 0.021476496829424745, 0.22040284777423805, 0.11020142388711902, 0.11020142388711902, 0.4408056955484761, 0.16457629793989953, 0.7405933407295479, 0.04114407448497488, 0.02057203724248744, 0.02057203724248744, 0.8846804224370761, 0.035387216897483045, 0.035387216897483045, 0.06995361967197847, 0.7694898163917632, 0.06995361967197847, 0.08449938159955987, 0.08449938159955987, 0.08449938159955987, 0.16899876319911974, 0.5914956711969191, 0.05273704179253076, 0.05273704179253076, 0.05273704179253076, 0.2636852089626538, 0.47463337613277684, 0.05273704179253076, 0.08722354719296382, 0.08722354719296382, 0.08722354719296382, 0.6977883775437106, 0.6291084881044605, 0.15727712202611513, 0.10321311132963805, 0.05652146572813513, 0.014744730189948294, 0.01965964025326439, 0.01965964025326439, 0.002457455031658049, 0.3903051633215799, 0.07696158150002984, 0.4727640006430404, 0.0054972558214307025, 0.01649176746429211, 0.03298353492858422, 0.011805916090527618, 0.023611832181055236, 0.9444732872422095, 0.011805916090527618, 0.3031106910700521, 0.06062213821401042, 0.06062213821401042, 0.06062213821401042, 0.5455992439260938, 0.10646163395155799, 0.10646163395155799, 0.10646163395155799, 0.6387698037093479, 0.11227320556562193, 0.11227320556562193, 0.11227320556562193, 0.6736392333937316, 0.0756821432143321, 0.8973739838270807, 0.010811734744904586, 0.010811734744904586, 0.06760878638022719, 0.8451098297528398, 0.033804393190113594, 0.09388660373599861, 0.7980361317559882, 0.046943301867999304, 0.9177914695228369, 0.026222613414938194, 0.026222613414938194, 0.5452745028577254, 0.19123371190270938, 0.20415490865289246, 0.010336957400146453, 0.010336957400146453, 0.033595111550475974, 0.005168478700073227, 0.4124989638619918, 0.3605305904620559, 0.09094465344988796, 0.05196837339993598, 0.05521639673743198, 0.016240116687479992, 0.012992093349983995, 0.9271858008694308, 0.023179645021735768, 0.023179645021735768, 0.944896396394898, 0.018527380321468587, 0.018527380321468587, 0.11035663592452447, 0.11035663592452447, 0.11035663592452447, 0.5517831796226224, 0.10679210942271784, 0.08899342451893154, 0.7653434508628112, 0.01779868490378631, 0.01779868490378631, 0.04738083107865188, 0.852854959415734, 0.04738083107865188, 0.8161015037146037, 0.04048122538266883, 0.09877418993371194, 0.012953992122454025, 0.0032384980306135063, 0.017811739168374287, 0.00971549409184052, 0.03979723081277913, 0.03979723081277913, 0.8755390778811409, 0.08597894546298421, 0.08597894546298421, 0.08597894546298421, 0.6878315637038737, 0.21003176153983844, 0.10501588076991922, 0.08401270461593537, 0.04200635230796768, 0.4830730515416284, 0.04200635230796768, 0.04200635230796768, 0.15833207770041816, 0.052777359233472716, 0.10555471846694543, 0.052777359233472716, 0.5805509515681999, 0.052777359233472716, 0.1061252187934413, 0.1061252187934413, 0.1061252187934413, 0.2122504375868826, 0.4245008751737652, 0.9353749495409132, 0.02175290580327705, 0.02175290580327705, 0.02175290580327705, 0.5301270770003919, 0.10194751480776766, 0.2089924053559237, 0.04587638166349545, 0.07646063610582575, 0.03568163018271868, 0.640562266823476, 0.14243090403486702, 0.15373494403763424, 0.022608080005534447, 0.013564848003320668, 0.01281124533646952, 0.01281124533646952, 0.0015072053337022964, 0.14705957088889135, 0.45588466975556324, 0.1323536138000022, 0.014705957088889136, 0.014705957088889136, 0.23529531342222618, 0.3111253658449213, 0.03889067073061516, 0.03889067073061516, 0.03889067073061516, 0.5833600609592274, 0.658411480373708, 0.17184346555208216, 0.10812622551591686, 0.025100730923337842, 0.011584952733848235, 0.01544660364513098, 0.009654127278206862, 0.12399741571846888, 0.12399741571846888, 0.37199224715540663, 0.12399741571846888, 0.12399741571846888, 0.12399741571846888, 0.5786486458908415, 0.31889969817984154, 0.07458138102593068, 0.010287087038059403, 0.007715315278544553, 0.005143543519029702, 0.005143543519029702, 0.04198590608702738, 0.04198590608702738, 0.04198590608702738, 0.04198590608702738, 0.8397181217405476, 0.6349328913698656, 0.26009299164548716, 0.07649793871926092, 0.015299587743852185, 0.005099862581284062, 0.002549931290642031, 0.002549931290642031, 0.05952552235150043, 0.029762761175750215, 0.029762761175750215, 0.029762761175750215, 0.833357312921006, 0.15111435473257162, 0.023248362266549482, 0.5695848755304622, 0.15111435473257162, 0.0581209056663737, 0.03487254339982422, 0.011624181133274741, 0.14928864364214506, 0.14928864364214506, 0.14928864364214506, 0.44786593092643523, 0.24867169065861963, 0.24867169065861963, 0.24867169065861963, 0.11464756876577642, 0.11464756876577642, 0.11464756876577642, 0.5732378438288821, 0.08222938443886046, 0.08222938443886046, 0.08222938443886046, 0.5756056910720233, 0.08222938443886046, 0.06214620684954751, 0.8286160913273002, 0.020715402283182503, 0.020715402283182503, 0.041430804566365005, 0.06025987401710217, 0.7833783622223283, 0.06025987401710217, 0.19501922003314526, 0.19501922003314526, 0.19501922003314526, 0.19501922003314526, 0.19501922003314526, 0.3881265409155924, 0.1940632704577962, 0.1940632704577962], \"Term\": [\"across_subject\", \"across_subject\", \"across_subject\", \"across_subject\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"activate\", \"activate\", \"activate\", \"activate\", \"activate\", \"activate\", \"activation\", \"activation\", \"activation\", \"activation\", \"activation\", \"activation\", \"activity\", \"activity\", \"activity\", \"activity\", \"activity\", \"activity\", \"activity\", \"adaboost\", \"adaboost\", \"adaboost\", \"adaboost\", \"add_delete\", \"add_delete\", \"add_delete\", \"admission\", \"admission\", \"admission\", \"agent\", \"agent\", \"agent\", \"alertness\", \"alertness\", \"alertness\", \"alertness\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"anarchy\", \"anarchy\", \"anarchy\", \"anarchy\", \"anatomic\", \"anatomic\", \"anatomic\", \"anatomic\", \"anatomical\", \"anatomical\", \"anatomical\", \"anatomical\", \"anatomical\", \"anatomical\", \"anatomical_constraint\", \"anatomical_constraint\", \"anatomical_constraint\", \"anatomical_constraint\", \"apprenticeship_learne\", \"apprenticeship_learne\", \"apprenticeship_learne\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"arm\", \"arm\", \"arm\", \"assembly\", \"assembly\", \"assembly\", \"assembly\", \"associative\", \"associative\", \"associative\", \"associative\", \"associative\", \"attractor\", \"attractor\", \"attractor\", \"attractor\", \"attractor\", \"attribute\", \"attribute\", \"attribute\", \"attribute\", \"attribute\", \"autocorrelation\", \"autocorrelation\", \"autocorrelation\", \"autocorrelation\", \"autocorrelation\", \"autocorrelation\", \"autoregressive\", \"autoregressive\", \"autoregressive\", \"autoregressive\", \"avlsi\", \"avlsi\", \"avlsi\", \"avlsi\", \"bandit\", \"bandit\", \"bandit\", \"bandit\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"ber\", \"ber\", \"ber\", \"ber\", \"best_attribute\", \"best_attribute\", \"best_attribute\", \"best_attribute\", \"bic\", \"bic\", \"bic\", \"blink\", \"blink\", \"blink\", \"border\", \"border\", \"border\", \"border\", \"border\", \"brain\", \"brain\", \"brain\", \"brain\", \"brain\", \"brain\", \"brain\", \"buckner\", \"buckner\", \"buckner\", \"bump\", \"bump\", \"bump\", \"bump\", \"cann\", \"cann\", \"cann\", \"cann\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"category\", \"category\", \"category\", \"category\", \"category\", \"category\", \"cby\", \"cby\", \"cby\", \"cby\", \"cd_mcboost\", \"cd_mcboost\", \"cd_mcboost\", \"cdma\", \"cdma\", \"cdma\", \"cdma\", \"cell\", \"cell\", \"cell\", \"cell\", \"cell\", \"cell\", \"cell\", \"center_frequencie\", \"center_frequencie\", \"center_frequencie\", \"center_frequencie\", \"center_location\", \"center_location\", \"center_location\", \"center_location\", \"centralized_gp\", \"centralized_gp\", \"centralized_gp\", \"centralized_gp\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"chip\", \"chip\", \"chip\", \"chip\", \"chip\", \"circuit\", \"circuit\", \"circuit\", \"circuit\", \"circuit\", \"circuit\", \"class\", \"class\", \"class\", \"class\", \"class\", \"class\", \"class\", \"classication_calibrate\", \"classication_calibrate\", \"classication_calibrate\", \"classication_calibration\", \"classication_calibration\", \"classication_calibration\", \"classification\", \"classification\", \"classification\", \"classification\", \"classification\", \"classification\", \"classification\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"cluster_center\", \"cluster_center\", \"cluster_center\", \"cluster_center\", \"clutter\", \"clutter\", \"clutter\", \"clutter\", \"code\", \"code\", \"code\", \"code\", \"code\", \"code\", \"code\", \"codeword\", \"codeword\", \"codeword\", \"coherence\", \"coherence\", \"coherence\", \"coherence\", \"coherence\", \"communication\", \"communication\", \"communication\", \"communication\", \"communication\", \"communication\", \"communication\", \"communication_cost\", \"communication_cost\", \"communication_cost\", \"communication_cost\", \"comp\", \"comp\", \"comp\", \"comp\", \"comp\", \"comp\", \"component\", \"component\", \"component\", \"component\", \"component\", \"component\", \"component\", \"concept\", \"concept\", \"concept\", \"concept\", \"concept\", \"connectivity\", \"connectivity\", \"connectivity\", \"connectivity\", \"connectivity\", \"connectivity\", \"connectomic\", \"connectomic\", \"connectomic\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consistency\", \"consistency\", \"consistency\", \"consistency\", \"consistency\", \"consistency\", \"consistency\", \"continuation\", \"continuation\", \"continuation\", \"continuation\", \"contribution\", \"contribution\", \"contribution\", \"contribution\", \"contribution\", \"contribution\", \"contribution\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"controller\", \"controller\", \"controller\", \"controller\", \"controller\", \"copula\", \"copula\", \"copula\", \"correlation\", \"correlation\", \"correlation\", \"correlation\", \"correlation\", \"correlation\", \"correlation\", \"cortical\", \"cortical\", \"cortical\", \"cortical\", \"cortical\", \"cortical\", \"cortical\", \"cortical\", \"coset_permutation\", \"coset_permutation\", \"coset_permutation\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"cps\", \"cps\", \"cps\", \"cps\", \"cricket\", \"cricket\", \"cricket\", \"cricket\", \"cricket\", \"current\", \"current\", \"current\", \"current\", \"current\", \"current\", \"current\", \"current_injection\", \"current_injection\", \"current_injection\", \"current_injection\", \"dag\", \"dag\", \"dag\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"decentralize\", \"decentralize\", \"decentralize\", \"decentralize\", \"decentralize\", \"decision_tree\", \"decision_tree\", \"decision_tree\", \"decision_tree\", \"decision_tree\", \"dendritic\", \"dendritic\", \"dendritic\", \"dendritic\", \"dendritic\", \"denotation\", \"denotation\", \"denotation\", \"denotation\", \"disparity\", \"disparity\", \"disparity\", \"disparity\", \"distance\", \"distance\", \"distance\", \"distance\", \"distance\", \"distance\", \"distance\", \"distance_measure\", \"distance_measure\", \"distance_measure\", \"distance_measure\", \"distinctiveness\", \"distinctiveness\", \"distinctiveness\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"duration\", \"duration\", \"duration\", \"duration\", \"duration\", \"duration\", \"dynamic\", \"dynamic\", \"dynamic\", \"dynamic\", \"dynamic\", \"dynamic\", \"dynamic\", \"dynamic\", \"dynamic_population\", \"dynamic_population\", \"dynamic_population\", \"dynamic_population\", \"eccentricity\", \"eccentricity\", \"eccentricity\", \"edge\", \"edge\", \"edge\", \"edge\", \"edge\", \"edge\", \"eeg\", \"eeg\", \"eeg\", \"eeg\", \"eeg\", \"energy\", \"energy\", \"energy\", \"energy\", \"energy\", \"energy\", \"energy\", \"engine\", \"engine\", \"engine\", \"engine\", \"engine\", \"eq\", \"eq\", \"eq\", \"eq\", \"eq\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"estimator\", \"estimator\", \"estimator\", \"estimator\", \"event\", \"event\", \"event\", \"event\", \"event\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"expert\", \"expert\", \"expert\", \"expert\", \"expert\", \"face\", \"face\", \"face\", \"face\", \"face\", \"face\", \"facial\", \"facial\", \"facial\", \"fast_convergence\", \"fast_convergence\", \"fast_convergence\", \"fast_convergence\", \"fast_convergence\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature_congestion\", \"feature_congestion\", \"feature_congestion\", \"feedback\", \"feedback\", \"feedback\", \"feedback\", \"feedback\", \"feedback\", \"fiber\", \"fiber\", \"fiber\", \"fiber\", \"fiber\", \"fig\", \"fig\", \"fig\", \"fig\", \"fig\", \"fig\", \"fig\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"filter\", \"filter\", \"filter\", \"filter\", \"filter\", \"filter\", \"filter\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"fixation\", \"fixation\", \"fixation\", \"flow\", \"flow\", \"flow\", \"flow\", \"flow\", \"flow\", \"flow\", \"fmri\", \"fmri\", \"fmri\", \"fmri\", \"fmri\", \"fnj\", \"fnj\", \"fnj\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"forest\", \"forest\", \"forest\", \"forest\", \"foveate\", \"foveate\", \"foveate\", \"frequency\", \"frequency\", \"frequency\", \"frequency\", \"frequency\", \"frequency\", \"frequency\", \"fric\", \"fric\", \"fric\", \"fric\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"functional\", \"functional\", \"functional\", \"functional\", \"functional\", \"functional\", \"functional\", \"functional\", \"functional_connectivity\", \"functional_connectivity\", \"functional_connectivity\", \"functional_connectivity\", \"gain\", \"gain\", \"gain\", \"gain\", \"gain\", \"gain\", \"game\", \"game\", \"game\", \"game\", \"gaussian_integral\", \"gaussian_integral\", \"gaussian_integral\", \"gaussian_processe\", \"gaussian_processe\", \"gaussian_processe\", \"gaussian_processe\", \"gbdt\", \"gbdt\", \"gbdt\", \"gbdt\", \"gcbn\", \"gcbn\", \"gcbn\", \"general\", \"general\", \"general\", \"general\", \"general\", \"general\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"global_vote\", \"global_vote\", \"global_vote\", \"global_vote\", \"gnkr\", \"gnkr\", \"gnkr\", \"gnkr\", \"gnkr_cs\", \"gnkr_cs\", \"gnkr_cs\", \"gnkr_cs\", \"gnkr_u\", \"gnkr_u\", \"gnkr_u\", \"gnkr_u\", \"gol\", \"gol\", \"gol\", \"gol\", \"gpr\", \"gpr\", \"gpr\", \"grammar\", \"grammar\", \"grammar\", \"grammar\", \"grammar\", \"granger\", \"granger\", \"granger\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"grate\", \"grate\", \"grate\", \"grate\", \"grating\", \"grating\", \"grating\", \"grating\", \"grift\", \"grift\", \"grift\", \"group\", \"group\", \"group\", \"group\", \"group\", \"group\", \"group\", \"gyrus\", \"gyrus\", \"gyrus\", \"gyrus\", \"hammer\", \"hammer\", \"hammer\", \"hawke\", \"hawke\", \"hawke\", \"hedge\", \"hedge\", \"hedge\", \"hedge\", \"histogram\", \"histogram\", \"histogram\", \"histogram\", \"histogram\", \"histogram\", \"histogram\", \"histogram\", \"hme\", \"hme\", \"hme\", \"hme\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"hz\", \"hz\", \"hz\", \"hz\", \"image\", \"image\", \"image\", \"image\", \"image\", \"image\", \"image\", \"imaging\", \"imaging\", \"imaging\", \"imaging\", \"imaging\", \"imaging\", \"importance\", \"importance\", \"importance\", \"importance\", \"importance\", \"importance\", \"importance\", \"individual\", \"individual\", \"individual\", \"individual\", \"individual\", \"individual\", \"individual\", \"individualized\", \"individualized\", \"individualized\", \"inhibition\", \"inhibition\", \"inhibition\", \"inhibition\", \"inner_loop\", \"inner_loop\", \"inner_loop\", \"inner_loop\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"interference\", \"interference\", \"interference\", \"interference\", \"interference\", \"interval\", \"interval\", \"interval\", \"interval\", \"interval\", \"interval\", \"interval\", \"intrinsic_reliability\", \"intrinsic_reliability\", \"intrinsic_reliability\", \"intrinsic_reliability\", \"item\", \"item\", \"item\", \"item\", \"jol\", \"jol\", \"jol\", \"jol\", \"jol\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"khz\", \"khz\", \"khz\", \"khz\", \"khz\", \"khz\", \"knn\", \"knn\", \"knn\", \"knn\", \"ktotal\", \"ktotal\", \"ktotal\", \"ktotal\", \"label\", \"label\", \"label\", \"label\", \"label\", \"label\", \"lag_parameter\", \"lag_parameter\", \"lag_parameter\", \"lag_parameter\", \"lancaster_interaction\", \"lancaster_interaction\", \"lancaster_interaction\", \"landmark\", \"landmark\", \"landmark\", \"landmark\", \"language\", \"language\", \"language\", \"language\", \"language\", \"laplace\", \"laplace\", \"laplace\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"latent\", \"latent\", \"latent\", \"latent\", \"latent\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"lexeme\", \"lexeme\", \"lexeme\", \"lexeme\", \"likelihood\", \"likelihood\", \"likelihood\", \"likelihood\", \"likelihood\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"liquid\", \"liquid\", \"liquid\", \"liquid\", \"local\", \"local\", \"local\", \"local\", \"local\", \"local\", \"local\", \"location\", \"location\", \"location\", \"location\", \"location\", \"location\", \"location\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"low_approximate\", \"low_approximate\", \"low_approximate\", \"low_approximate\", \"low_resolution\", \"low_resolution\", \"low_resolution\", \"lower_bound\", \"lower_bound\", \"lower_bound\", \"lower_bound\", \"lower_bound\", \"lower_bound\", \"luce\", \"luce\", \"luce\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"mallow\", \"mallow\", \"mallow\", \"mallow\", \"map\", \"map\", \"map\", \"map\", \"map\", \"map\", \"map\", \"map\", \"marginal\", \"marginal\", \"marginal\", \"marginal\", \"markov_chain\", \"markov_chain\", \"markov_chain\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matroid\", \"matroid\", \"matroid\", \"mdn\", \"mdn\", \"mdn\", \"mdn\", \"mdp\", \"mdp\", \"mdp\", \"mds\", \"mds\", \"mds\", \"mean_field\", \"mean_field\", \"mean_field\", \"metabolic\", \"metabolic\", \"metabolic\", \"metabolic\", \"metabolic_constraint\", \"metabolic_constraint\", \"metabolic_constraint\", \"metabolic_constraint\", \"metabolic_cost\", \"metabolic_cost\", \"metabolic_cost\", \"metabolic_cost\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"mgp\", \"mgp\", \"mgp\", \"mia\", \"mia\", \"mia\", \"mia\", \"microcircuit\", \"microcircuit\", \"microcircuit\", \"microcircuit\", \"mismatch_error\", \"mismatch_error\", \"mismatch_error\", \"mismatch_error\", \"misspecifie\", \"misspecifie\", \"misspecifie\", \"misspecifie\", \"misspecifie\", \"mix\", \"mix\", \"mix\", \"mix\", \"mix\", \"mixture\", \"mixture\", \"mixture\", \"mixture\", \"mixture\", \"mjolsness\", \"mjolsness\", \"mjolsness\", \"mjolsness\", \"mkl\", \"mkl\", \"mkl\", \"mmse\", \"mmse\", \"mmse\", \"mmse\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"mog\", \"mog\", \"mog\", \"monotonic\", \"monotonic\", \"monotonic\", \"monotonic\", \"morph\", \"morph\", \"morph\", \"morphology\", \"morphology\", \"morphology\", \"morphology\", \"motion\", \"motion\", \"motion\", \"motion\", \"motion\", \"mud\", \"mud\", \"mud\", \"mud\", \"multiuser_detection\", \"multiuser_detection\", \"multiuser_detection\", \"multiuser_detection\", \"net\", \"net\", \"net\", \"net\", \"net\", \"net\", \"net\", \"network\", \"network\", \"network\", \"network\", \"network\", \"network\", \"network\", \"network\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neuroimage\", \"neuroimage\", \"neuroimage\", \"neuroimage\", \"neuroimage\", \"neuroimage\", \"neuron\", \"neuron\", \"neuron\", \"neuron\", \"neuron\", \"neuron\", \"neuron\", \"nf\", \"nf\", \"nf\", \"nf\", \"node\", \"node\", \"node\", \"node\", \"node\", \"node\", \"noise\", \"noise\", \"noise\", \"noise\", \"noise\", \"noise\", \"noise\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"nystrm\", \"nystrm\", \"nystrm\", \"nystrm\", \"object\", \"object\", \"object\", \"object\", \"object\", \"object\", \"objective\", \"objective\", \"objective\", \"objective\", \"objective\", \"objective\", \"objective\", \"observation\", \"observation\", \"observation\", \"observation\", \"observation\", \"observation\", \"occipital\", \"occipital\", \"occipital\", \"opm\", \"opm\", \"opm\", \"opm\", \"optical_flow\", \"optical_flow\", \"optical_flow\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"optimize\", \"optimize\", \"optimize\", \"optimize\", \"optimize\", \"optimize\", \"optimize\", \"optimize\", \"orbit\", \"orbit\", \"orbit\", \"orbit\", \"orbitope\", \"orbitope\", \"orbitope\", \"orbitope\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"outer_loop\", \"outer_loop\", \"outer_loop\", \"outer_loop\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"parallel\", \"parallel\", \"parallel\", \"parallel\", \"parallel\", \"parallel\", \"parallel\", \"parallelize\", \"parallelize\", \"parallelize\", \"parallelize\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parcellation\", \"parcellation\", \"parcellation\", \"parcellation\", \"pass_delay\", \"pass_delay\", \"pass_delay\", \"pass_delay\", \"patch\", \"patch\", \"patch\", \"patch\", \"pattern\", \"pattern\", \"pattern\", \"pattern\", \"pattern\", \"pattern\", \"pattern\", \"penetrate\", \"penetrate\", \"penetrate\", \"penetrate\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"peripheral_architecture\", \"peripheral_architecture\", \"peripheral_architecture\", \"permutation\", \"permutation\", \"permutation\", \"permutation\", \"permutation\", \"phase\", \"phase\", \"phase\", \"phase\", \"phase\", \"phase\", \"phase\", \"phase_tune\", \"phase_tune\", \"phase_tune\", \"phase_tune\", \"phonetic\", \"phonetic\", \"phonetic\", \"phonetic\", \"phonetic\", \"photosensor\", \"photosensor\", \"photosensor\", \"photosensor\", \"pifc\", \"pifc\", \"pifc\", \"pitch\", \"pitch\", \"pitch\", \"pitch\", \"planner\", \"planner\", \"planner\", \"planner\", \"planner\", \"planning\", \"planning\", \"planning\", \"planning\", \"planning\", \"plant\", \"plant\", \"plant\", \"player\", \"player\", \"player\", \"player\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"pole\", \"pole\", \"pole\", \"policy\", \"policy\", \"policy\", \"policy\", \"policy\", \"polymom\", \"polymom\", \"polymom\", \"population\", \"population\", \"population\", \"population\", \"population\", \"population\", \"position\", \"position\", \"position\", \"position\", \"position\", \"position\", \"pre_image\", \"pre_image\", \"pre_image\", \"pre_image\", \"pre_image\", \"precuneus\", \"precuneus\", \"precuneus\", \"precuneus\", \"preferred\", \"preferred\", \"preferred\", \"preferred\", \"preferred\", \"privacy\", \"privacy\", \"privacy\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"profile\", \"profile\", \"profile\", \"profile\", \"profile\", \"profile\", \"profile\", \"program\", \"program\", \"program\", \"program\", \"program\", \"program\", \"pv_tree\", \"pv_tree\", \"pv_tree\", \"pv_tree\", \"qr\", \"qr\", \"qr\", \"qr\", \"quadrant\", \"quadrant\", \"quadrant\", \"quantizer\", \"quantizer\", \"quantizer\", \"quantizer\", \"query\", \"query\", \"query\", \"query\", \"rank\", \"rank\", \"rank\", \"rank\", \"rank\", \"rank\", \"rank\", \"rank_aggregation\", \"rank_aggregation\", \"rank_aggregation\", \"rank_aggregation\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"readout\", \"readout\", \"readout\", \"readout\", \"readout_neuron\", \"readout_neuron\", \"readout_neuron\", \"readout_neuron\", \"realize\", \"realize\", \"realize\", \"realize\", \"realize\", \"receiver\", \"receiver\", \"receiver\", \"receiver\", \"receptive_field\", \"receptive_field\", \"receptive_field\", \"receptive_field\", \"receptive_field\", \"recursive_teache\", \"recursive_teache\", \"recursive_teache\", \"recursive_teache\", \"redundancy\", \"redundancy\", \"redundancy\", \"redundancy\", \"redundancy\", \"refinement\", \"refinement\", \"refinement\", \"region\", \"region\", \"region\", \"region\", \"region\", \"region\", \"region\", \"regression\", \"regression\", \"regression\", \"regression\", \"regression\", \"regression\", \"regression\", \"regret\", \"regret\", \"regret\", \"regret\", \"reinforcement_learne\", \"reinforcement_learne\", \"reinforcement_learne\", \"reinforcement_learne\", \"relational\", \"relational\", \"relational\", \"representation\", \"representation\", \"representation\", \"representation\", \"representation\", \"representation\", \"response\", \"response\", \"response\", \"response\", \"response\", \"response\", \"response\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"returning_time\", \"returning_time\", \"returning_time\", \"reward\", \"reward\", \"reward\", \"reward\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"robot\", \"robot\", \"robot\", \"robot\", \"robot\", \"robot\", \"roi\", \"roi\", \"roi\", \"roi\", \"rois\", \"rois\", \"rois\", \"rois\", \"rtd\", \"rtd\", \"rtd\", \"rtd\", \"rtd_vcd\", \"rtd_vcd\", \"rtd_vcd\", \"rtd_vcd\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"sampler\", \"sampler\", \"sampler\", \"sampler\", \"sancetta\", \"sancetta\", \"sancetta\", \"sancetta\", \"sc\", \"sc\", \"sc\", \"sc\", \"scalp\", \"scalp\", \"scalp\", \"scalp\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"seed\", \"seed\", \"seed\", \"seed\", \"seed\", \"segment\", \"segment\", \"segment\", \"segment\", \"segment\", \"segment\", \"selection\", \"selection\", \"selection\", \"selection\", \"selection\", \"semantic\", \"semantic\", \"semantic\", \"semantic\", \"session\", \"session\", \"session\", \"session\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"shape\", \"shape\", \"shape\", \"shape\", \"shape\", \"shape\", \"shape\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"shrinkage\", \"shrinkage\", \"shrinkage\", \"shrinkage\", \"similar\", \"similar\", \"similar\", \"similar\", \"similar\", \"similar\", \"similar\", \"similar\", \"simulated_anneale\", \"simulated_anneale\", \"simulated_anneale\", \"simulated_anneale\", \"sine_wave\", \"sine_wave\", \"sine_wave\", \"sine_wave\", \"site\", \"site\", \"site\", \"site\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"sls\", \"sls\", \"sls\", \"small\", \"small\", \"small\", \"small\", \"small\", \"small\", \"small\", \"smt\", \"smt\", \"smt\", \"smt\", \"solution\", \"solution\", \"solution\", \"solution\", \"solution\", \"solution\", \"solution\", \"solve\", \"solve\", \"solve\", \"solve\", \"solve\", \"solve\", \"solve\", \"sonorant\", \"sonorant\", \"sonorant\", \"sonorant\", \"sound\", \"sound\", \"sound\", \"sound\", \"sound\", \"sound\", \"source\", \"source\", \"source\", \"source\", \"source\", \"source\", \"source\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"sparse\", \"sparse\", \"sparse\", \"sparse\", \"sparse\", \"sparse\", \"sparse_pca\", \"sparse_pca\", \"sparse_pca\", \"spatial_frequency\", \"spatial_frequency\", \"spatial_frequency\", \"spatial_frequency\", \"spatio_temporal\", \"spatio_temporal\", \"spatio_temporal\", \"spatio_temporal\", \"speaker\", \"speaker\", \"speaker\", \"speaker\", \"speaker\", \"speaker\", \"spectrogram\", \"spectrogram\", \"spectrogram\", \"spectrogram\", \"spike\", \"spike\", \"spike\", \"spike\", \"spike\", \"spike\", \"spike\", \"spike_train\", \"spike_train\", \"spike_train\", \"spike_train\", \"spike_train\", \"spline\", \"spline\", \"spline\", \"spline\", \"sporn\", \"sporn\", \"sporn\", \"spread\", \"spread\", \"spread\", \"spread\", \"spread\", \"standard_shrinkage\", \"standard_shrinkage\", \"standard_shrinkage\", \"standard_shrinkage\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"std\", \"std\", \"std\", \"std\", \"stem\", \"stem\", \"stem\", \"stem\", \"stf\", \"stf\", \"stf\", \"stf\", \"stimulus\", \"stimulus\", \"stimulus\", \"stimulus\", \"stimulus\", \"stimulus\", \"stimulus\", \"structural\", \"structural\", \"structural\", \"structural\", \"structural\", \"structural\", \"structural_connectivity\", \"structural_connectivity\", \"structural_connectivity\", \"structural_connectivity\", \"student\", \"student\", \"student\", \"subject\", \"subject\", \"subject\", \"subject\", \"subject\", \"subject\", \"subject\", \"subsample\", \"subsample\", \"subsample\", \"subsample\", \"surrogate\", \"surrogate\", \"surrogate\", \"surrogate\", \"surrogate\", \"svr\", \"svr\", \"svr\", \"symmetric_phase\", \"symmetric_phase\", \"symmetric_phase\", \"synapsis\", \"synapsis\", \"synapsis\", \"synapsis\", \"synapsis\", \"synaptic\", \"synaptic\", \"synaptic\", \"synaptic\", \"synaptic\", \"synaptic\", \"synaptic_depression\", \"synaptic_depression\", \"synaptic_depression\", \"synaptic_depression\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"target\", \"target\", \"target\", \"target\", \"target\", \"target\", \"taxonomy\", \"taxonomy\", \"taxonomy\", \"taxonomy\", \"teach\", \"teach\", \"teach\", \"teach\", \"teach\", \"temporal_frequency\", \"temporal_frequency\", \"temporal_frequency\", \"temporal_frequency\", \"tense\", \"tense\", \"tense\", \"tense\", \"tensor\", \"tensor\", \"tensor\", \"tensor\", \"tensor_decomposition\", \"tensor_decomposition\", \"tensor_decomposition\", \"tensor_pow\", \"tensor_pow\", \"tensor_pow\", \"terrain\", \"terrain\", \"terrain\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"timeline_tree\", \"timeline_tree\", \"timeline_tree\", \"timestamp\", \"timestamp\", \"timestamp\", \"top_attribute\", \"top_attribute\", \"top_attribute\", \"top_attribute\", \"topic\", \"topic\", \"topic\", \"topic\", \"topic\", \"total_independence\", \"total_independence\", \"total_independence\", \"training\", \"training\", \"training\", \"training\", \"training\", \"training\", \"training\", \"treecutter\", \"treecutter\", \"treecutter\", \"tsmin\", \"tsmin\", \"tsmin\", \"tsmin\", \"tune\", \"tune\", \"tune\", \"tune\", \"tune\", \"tune\", \"tune\", \"tuning\", \"tuning\", \"tuning\", \"tuning\", \"tuning\", \"tuning\", \"tuning_curve\", \"tuning_curve\", \"tuning_curve\", \"tuning_curve\", \"tuning_curve\", \"ulsif\", \"ulsif\", \"ulsif\", \"ulsif\", \"unit\", \"unit\", \"unit\", \"unit\", \"unit\", \"unit\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"user\", \"user\", \"user\", \"user\", \"user\", \"user\", \"utterance\", \"utterance\", \"utterance\", \"utterance\", \"utterance\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"variability\", \"variability\", \"variability\", \"variability\", \"variability\", \"variability\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable\", \"vcd\", \"vcd\", \"vcd\", \"vcd\", \"vcd\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"velocity\", \"velocity\", \"velocity\", \"velocity\", \"velocity\", \"visual\", \"visual\", \"visual\", \"visual\", \"visual\", \"visual\", \"visual\", \"voc\", \"voc\", \"voc\", \"voc\", \"volumetric\", \"volumetric\", \"volumetric\", \"voting\", \"voting\", \"voting\", \"voting\", \"wave\", \"wave\", \"wave\", \"wave\", \"wave\", \"waveform\", \"waveform\", \"waveform\", \"waveform\", \"waveform\", \"wishart\", \"wishart\", \"wishart\", \"working_memory\", \"working_memory\", \"working_memory\", \"working_memory\", \"working_memory\", \"yellow\", \"yellow\", \"yellow\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 1, 5, 8, 7, 2, 6, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el2711400031015764323834778114\", ldavis_el2711400031015764323834778114_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el2711400031015764323834778114\", ldavis_el2711400031015764323834778114_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el2711400031015764323834778114\", ldavis_el2711400031015764323834778114_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "3      0.137544 -0.004543       1        1  49.940127\n",
       "0      0.073185 -0.046892       2        1  17.214396\n",
       "4      0.065348  0.070652       3        1  16.301684\n",
       "7     -0.002093 -0.031953       4        1   6.297177\n",
       "6     -0.045438  0.014392       5        1   4.181911\n",
       "1     -0.045893 -0.005014       6        1   2.795634\n",
       "5     -0.064248  0.003588       7        1   2.606953\n",
       "2     -0.118405 -0.000230       8        1   0.662119, topic_info=         Term         Freq        Total Category  logprob  loglift\n",
       "522     state   479.000000   479.000000  Default  30.0000  30.0000\n",
       "353     model  1853.000000  1853.000000  Default  29.0000  29.0000\n",
       "185     error   356.000000   356.000000  Default  28.0000  28.0000\n",
       "760     input   546.000000   546.000000  Default  27.0000  27.0000\n",
       "373    neural   375.000000   375.000000  Default  26.0000  26.0000\n",
       "...       ...          ...          ...      ...      ...      ...\n",
       "1125    human     1.284217   109.523817   Topic8  -6.8599   0.5715\n",
       "404   pattern     1.366550   156.594159   Topic8  -6.7978   0.2761\n",
       "587       use     2.019497  1326.959211   Topic8  -6.4072  -1.4703\n",
       "791       map     1.297383   304.590507   Topic8  -6.8497  -0.4411\n",
       "1109    group     1.163694   107.771435   Topic8  -6.9585   0.4891\n",
       "\n",
       "[548 rows x 6 columns], token_table=      Topic      Freq            Term\n",
       "term                                 \n",
       "956       1  0.192137  across_subject\n",
       "956       2  0.192137  across_subject\n",
       "956       3  0.192137  across_subject\n",
       "956       8  0.192137  across_subject\n",
       "1350      1  0.486833          action\n",
       "...     ...       ...             ...\n",
       "1346      4  0.195019  working_memory\n",
       "1346      8  0.195019  working_memory\n",
       "1347      1  0.388127          yellow\n",
       "1347      2  0.194063          yellow\n",
       "1347      3  0.194063          yellow\n",
       "\n",
       "[2132 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 1, 5, 8, 7, 2, 6, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!mkdir results\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "\n",
    "num_topics = 8\n",
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "LDAvis_data_filepath = os.path.join('results/ldavis_tuned_'+str(num_topics))\n",
    "\n",
    "# # this is a bit time consuming - make the if statement True\n",
    "# # if you want to execute visualization prep yourself\n",
    "if 1 == 1:\n",
    "    LDAvis_prepared = gensimvis.prepare(lda_model, corpus, id2word)\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "\n",
    "# load the pre-prepared pyLDAvis data from disk\n",
    "with open(LDAvis_data_filepath, 'rb') as f:\n",
    "    LDAvis_prepared = pickle.load(f)\n",
    "\n",
    "pyLDAvis.save_html(LDAvis_prepared, 'results/ldavis_tuned_'+ str(num_topics) +'.html')\n",
    "\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** **\n",
    "#### Closing Notes\n",
    "\n",
    "We started with understanding why evaluating the topic model is essential. Next, we reviewed existing methods and scratched the surface of topic coherence, along with the available coherence measures. Then we built a default LDA model using Gensim implementation to establish the baseline coherence score and reviewed practical ways to optimize the LDA hyperparameters.\n",
    "\n",
    "Hopefully, this article has managed to shed light on the underlying topic evaluation strategies, and intuitions behind it.\n",
    "\n",
    "** **\n",
    "#### References:\n",
    "1. http://qpleple.com/perplexity-to-evaluate-topic-models/\n",
    "2. https://www.amazon.com/Machine-Learning-Probabilistic-Perspective-Computation/dp/0262018020\n",
    "3. https://papers.nips.cc/paper/3700-reading-tea-leaves-how-humans-interpret-topic-models.pdf\n",
    "4. https://github.com/mattilyra/pydataberlin-2017/blob/master/notebook/EvaluatingUnsupervisedModels.ipynb\n",
    "5. https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/\n",
    "6. http://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf\n",
    "7. http://palmetto.aksw.org/palmetto-webapp/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
