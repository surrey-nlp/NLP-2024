{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "happy-sigma",
      "metadata": {
        "id": "happy-sigma"
      },
      "source": [
        "# Lab 01 - Tokenisation and basic feature vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "downtown-supervision",
      "metadata": {
        "id": "downtown-supervision"
      },
      "source": [
        "This lab is an introduction to some basic test processing that will give us the first impression of the challenges in translating text into meaningful feature vector representations.\n",
        "\n",
        "So let's first set some text..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "stopped-throat",
      "metadata": {
        "id": "stopped-throat"
      },
      "outputs": [],
      "source": [
        "sentence = \"\"\" Welcome to the Natural Language Processing lab!\n",
        "               We'll learn many things in this no 1 lab, so we will take it easy.\n",
        "               Natural Language Processing is fun.\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86574662",
      "metadata": {
        "id": "86574662"
      },
      "source": [
        "Let's also download some libraries we'll be using:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aKciRQkx0Vze"
      },
      "id": "aKciRQkx0Vze"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "76028587",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76028587",
        "outputId": "8b33a989-1d49-4941-c6d7-b5203807ffc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install numpy pandas scikit-learn nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28da2c66",
      "metadata": {
        "id": "28da2c66"
      },
      "source": [
        "## Using native Python functions for tokenisation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "southwest-perry",
      "metadata": {
        "id": "southwest-perry"
      },
      "source": [
        "Let's try to split the text based on spaces using the built in string function `split()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "careful-cleaning",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "careful-cleaning",
        "outputId": "d9c3129f-2814-4205-bc76-ffc6424ede22"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Welcome',\n",
              " 'to',\n",
              " 'the',\n",
              " 'Natural',\n",
              " 'Language',\n",
              " 'Processing',\n",
              " 'lab!',\n",
              " \"We'll\",\n",
              " 'learn',\n",
              " 'many',\n",
              " 'things',\n",
              " 'in',\n",
              " 'this',\n",
              " 'no',\n",
              " '1',\n",
              " 'lab,',\n",
              " 'so',\n",
              " 'we',\n",
              " 'will',\n",
              " 'take',\n",
              " 'it',\n",
              " 'easy.',\n",
              " 'Natural',\n",
              " 'Language',\n",
              " 'Processing',\n",
              " 'is',\n",
              " 'fun.']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "sentence.split()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mounted-brain",
      "metadata": {
        "id": "mounted-brain"
      },
      "source": [
        "You will observe that some words are not well separated from punctuation and contain some appended onto them.\n",
        "So we need to find a way to remove those characters... but, before we do that, let's see how we can create a quick feature vector first!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "regional-services",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "regional-services",
        "outputId": "96506f22-3267-49ea-848f-5f3ac2ffe05a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1',\n",
              " 'Language',\n",
              " 'Natural',\n",
              " 'Processing',\n",
              " \"We'll\",\n",
              " 'Welcome',\n",
              " 'easy.',\n",
              " 'fun.',\n",
              " 'in',\n",
              " 'is',\n",
              " 'it',\n",
              " 'lab!',\n",
              " 'lab,',\n",
              " 'learn',\n",
              " 'many',\n",
              " 'no',\n",
              " 'so',\n",
              " 'take',\n",
              " 'the',\n",
              " 'things',\n",
              " 'this',\n",
              " 'to',\n",
              " 'we',\n",
              " 'will']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "tokens = sentence.split()  # splitting based on spaces\n",
        "vocab = sorted(set(tokens))  # sorting and removing duplicates by using set()\n",
        "vocab  # just printing the vocab so we can look at it"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hundred-syndication",
      "metadata": {
        "id": "hundred-syndication"
      },
      "source": [
        "We can see that the sorted list has the numbers first, followed by capital and then lower case letters (all alphabetically sorted). We also see that repeating words appear only once in our vocabulary list. Let's compare the size of the two lists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "periodic-typing",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "periodic-typing",
        "outputId": "0a4b53a0-9ef0-4b86-fe2d-0a22b19dbe95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: 27\n",
            "Vocab: 24\n"
          ]
        }
      ],
      "source": [
        "tokens_len = len(tokens)\n",
        "vocab_len = len(vocab)\n",
        "\n",
        "print(f\"Tokens: {tokens_len}\")\n",
        "print(f\"Vocab: {vocab_len}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "published-private",
      "metadata": {
        "id": "published-private"
      },
      "source": [
        "Let's try and print the matrix of tokens against vocabulary. We will use the numpy lib for that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ultimate-litigation",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ultimate-litigation",
        "outputId": "beaf4516-8cd4-4277-8d21-eff58da3a684"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "        0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "matrix = np.zeros((tokens_len, vocab_len), int)\n",
        "for i, token in enumerate(tokens):\n",
        "    matrix[i, vocab.index(token)] = 1\n",
        "\n",
        "matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "designed-beach",
      "metadata": {
        "id": "designed-beach"
      },
      "source": [
        "It's not easy to see, but the second, third and fourth columns have the value of 1 in two rows, whereas the rest only take the value of 1 in a single row. To make it a little more readable, we could use Pandas and DataFrame! Both Pandas and NumPy are very useful libs that we will use many times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "realistic-wallace",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 925
        },
        "id": "realistic-wallace",
        "outputId": "31ba3188-1fe2-4349-e150-1474c98e4a07"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    1  Language  Natural  Processing  We'll  Welcome  easy.  fun.  in  is  \\\n",
              "0   0         0        0           0      0        1      0     0   0   0   \n",
              "1   0         0        0           0      0        0      0     0   0   0   \n",
              "2   0         0        0           0      0        0      0     0   0   0   \n",
              "3   0         0        1           0      0        0      0     0   0   0   \n",
              "4   0         1        0           0      0        0      0     0   0   0   \n",
              "5   0         0        0           1      0        0      0     0   0   0   \n",
              "6   0         0        0           0      0        0      0     0   0   0   \n",
              "7   0         0        0           0      1        0      0     0   0   0   \n",
              "8   0         0        0           0      0        0      0     0   0   0   \n",
              "9   0         0        0           0      0        0      0     0   0   0   \n",
              "10  0         0        0           0      0        0      0     0   0   0   \n",
              "11  0         0        0           0      0        0      0     0   1   0   \n",
              "12  0         0        0           0      0        0      0     0   0   0   \n",
              "13  0         0        0           0      0        0      0     0   0   0   \n",
              "14  1         0        0           0      0        0      0     0   0   0   \n",
              "15  0         0        0           0      0        0      0     0   0   0   \n",
              "16  0         0        0           0      0        0      0     0   0   0   \n",
              "17  0         0        0           0      0        0      0     0   0   0   \n",
              "18  0         0        0           0      0        0      0     0   0   0   \n",
              "19  0         0        0           0      0        0      0     0   0   0   \n",
              "20  0         0        0           0      0        0      0     0   0   0   \n",
              "21  0         0        0           0      0        0      1     0   0   0   \n",
              "22  0         0        1           0      0        0      0     0   0   0   \n",
              "23  0         1        0           0      0        0      0     0   0   0   \n",
              "24  0         0        0           1      0        0      0     0   0   0   \n",
              "25  0         0        0           0      0        0      0     0   0   1   \n",
              "26  0         0        0           0      0        0      0     1   0   0   \n",
              "\n",
              "    ...  many  no  so  take  the  things  this  to  we  will  \n",
              "0   ...     0   0   0     0    0       0     0   0   0     0  \n",
              "1   ...     0   0   0     0    0       0     0   1   0     0  \n",
              "2   ...     0   0   0     0    1       0     0   0   0     0  \n",
              "3   ...     0   0   0     0    0       0     0   0   0     0  \n",
              "4   ...     0   0   0     0    0       0     0   0   0     0  \n",
              "5   ...     0   0   0     0    0       0     0   0   0     0  \n",
              "6   ...     0   0   0     0    0       0     0   0   0     0  \n",
              "7   ...     0   0   0     0    0       0     0   0   0     0  \n",
              "8   ...     0   0   0     0    0       0     0   0   0     0  \n",
              "9   ...     1   0   0     0    0       0     0   0   0     0  \n",
              "10  ...     0   0   0     0    0       1     0   0   0     0  \n",
              "11  ...     0   0   0     0    0       0     0   0   0     0  \n",
              "12  ...     0   0   0     0    0       0     1   0   0     0  \n",
              "13  ...     0   1   0     0    0       0     0   0   0     0  \n",
              "14  ...     0   0   0     0    0       0     0   0   0     0  \n",
              "15  ...     0   0   0     0    0       0     0   0   0     0  \n",
              "16  ...     0   0   1     0    0       0     0   0   0     0  \n",
              "17  ...     0   0   0     0    0       0     0   0   1     0  \n",
              "18  ...     0   0   0     0    0       0     0   0   0     1  \n",
              "19  ...     0   0   0     1    0       0     0   0   0     0  \n",
              "20  ...     0   0   0     0    0       0     0   0   0     0  \n",
              "21  ...     0   0   0     0    0       0     0   0   0     0  \n",
              "22  ...     0   0   0     0    0       0     0   0   0     0  \n",
              "23  ...     0   0   0     0    0       0     0   0   0     0  \n",
              "24  ...     0   0   0     0    0       0     0   0   0     0  \n",
              "25  ...     0   0   0     0    0       0     0   0   0     0  \n",
              "26  ...     0   0   0     0    0       0     0   0   0     0  \n",
              "\n",
              "[27 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1e91afb1-e5fb-4e20-9ea0-1c4c647a5bf3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>Language</th>\n",
              "      <th>Natural</th>\n",
              "      <th>Processing</th>\n",
              "      <th>We'll</th>\n",
              "      <th>Welcome</th>\n",
              "      <th>easy.</th>\n",
              "      <th>fun.</th>\n",
              "      <th>in</th>\n",
              "      <th>is</th>\n",
              "      <th>...</th>\n",
              "      <th>many</th>\n",
              "      <th>no</th>\n",
              "      <th>so</th>\n",
              "      <th>take</th>\n",
              "      <th>the</th>\n",
              "      <th>things</th>\n",
              "      <th>this</th>\n",
              "      <th>to</th>\n",
              "      <th>we</th>\n",
              "      <th>will</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>27 rows Ã— 24 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e91afb1-e5fb-4e20-9ea0-1c4c647a5bf3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1e91afb1-e5fb-4e20-9ea0-1c4c647a5bf3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1e91afb1-e5fb-4e20-9ea0-1c4c647a5bf3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5e7931d6-1fed-491d-bb2a-ffa0391c4b93\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5e7931d6-1fed-491d-bb2a-ffa0391c4b93')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5e7931d6-1fed-491d-bb2a-ffa0391c4b93 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.DataFrame(matrix, columns=vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "increasing-barrel",
      "metadata": {
        "id": "increasing-barrel"
      },
      "source": [
        "Now this is a lot more clear and if we wanted we could carry on making it look nicer.\n",
        "\n",
        "Let's now carry on building the bag of words (BoW) -\n",
        "- *Bags of words (BoW) are a basic representation technique used in NLP.*\n",
        "- *Its main purpose is to convert textual data into a numerical format that can be used for further analysis.*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "anonymous-anaheim",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anonymous-anaheim",
        "outputId": "f2ab60c0-016a-4d9f-b23b-e6ae2929ab21"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1', 1),\n",
              " ('Language', 1),\n",
              " ('Natural', 1),\n",
              " ('Processing', 1),\n",
              " (\"We'll\", 1),\n",
              " ('Welcome', 1),\n",
              " ('easy.', 1),\n",
              " ('fun.', 1),\n",
              " ('in', 1),\n",
              " ('is', 1),\n",
              " ('it', 1),\n",
              " ('lab!', 1),\n",
              " ('lab,', 1),\n",
              " ('learn', 1),\n",
              " ('many', 1),\n",
              " ('no', 1),\n",
              " ('so', 1),\n",
              " ('take', 1),\n",
              " ('the', 1),\n",
              " ('things', 1),\n",
              " ('this', 1),\n",
              " ('to', 1),\n",
              " ('we', 1),\n",
              " ('will', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "bow = {token: 1 for token in tokens}  # setting this up as a dictionary\n",
        "sorted(bow.items())  # lets print it"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "better-palestine",
      "metadata": {
        "id": "better-palestine"
      },
      "source": [
        "Since bow is a dictionary, we see that there are no duplicate words.\n",
        "\n",
        "Pandas also has a more efficient form of a dictionary called `Series`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "adequate-aquatic",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "adequate-aquatic",
        "outputId": "e1b69c4b-a32b-4567-fa69-7f26dc14d934"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Welcome  to  the  Natural  Language  Processing  lab!  We'll  learn  \\\n",
              "sent        1   1    1        1         1           1     1      1      1   \n",
              "\n",
              "      many  ...  1  lab,  so  we  will  take  it  easy.  is  fun.  \n",
              "sent     1  ...  1     1   1   1     1     1   1      1   1     1  \n",
              "\n",
              "[1 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-76560c2f-a817-4093-bf43-17e8a8268c72\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Welcome</th>\n",
              "      <th>to</th>\n",
              "      <th>the</th>\n",
              "      <th>Natural</th>\n",
              "      <th>Language</th>\n",
              "      <th>Processing</th>\n",
              "      <th>lab!</th>\n",
              "      <th>We'll</th>\n",
              "      <th>learn</th>\n",
              "      <th>many</th>\n",
              "      <th>...</th>\n",
              "      <th>1</th>\n",
              "      <th>lab,</th>\n",
              "      <th>so</th>\n",
              "      <th>we</th>\n",
              "      <th>will</th>\n",
              "      <th>take</th>\n",
              "      <th>it</th>\n",
              "      <th>easy.</th>\n",
              "      <th>is</th>\n",
              "      <th>fun.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>sent</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows Ã— 24 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76560c2f-a817-4093-bf43-17e8a8268c72')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-76560c2f-a817-4093-bf43-17e8a8268c72 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-76560c2f-a817-4093-bf43-17e8a8268c72');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df = pd.DataFrame(pd.Series(dict([(token, 1) for token in tokens])), columns=[\"sent\"]).T\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "senior-shareware",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "senior-shareware",
        "outputId": "3f40f941-843d-480a-90a1-331fe9c4dc66"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Welcome  to  the  Natural  Language  Processing  lab!  We'll  learn  \\\n",
              "sent0        1   1    1        1         1           1     1      0      0   \n",
              "sent1        0   0    0        0         0           0     0      1      1   \n",
              "sent2        0   0    0        1         1           1     0      0      0   \n",
              "\n",
              "       many  ...  1  lab,  so  we  will  take  it  easy.  is  fun.  \n",
              "sent0     0  ...  0     0   0   0     0     0   0      0   0     0  \n",
              "sent1     1  ...  1     1   1   1     1     1   1      1   0     0  \n",
              "sent2     0  ...  0     0   0   0     0     0   0      0   1     1  \n",
              "\n",
              "[3 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06c4b0dd-b075-4602-9934-191020afe101\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Welcome</th>\n",
              "      <th>to</th>\n",
              "      <th>the</th>\n",
              "      <th>Natural</th>\n",
              "      <th>Language</th>\n",
              "      <th>Processing</th>\n",
              "      <th>lab!</th>\n",
              "      <th>We'll</th>\n",
              "      <th>learn</th>\n",
              "      <th>many</th>\n",
              "      <th>...</th>\n",
              "      <th>1</th>\n",
              "      <th>lab,</th>\n",
              "      <th>so</th>\n",
              "      <th>we</th>\n",
              "      <th>will</th>\n",
              "      <th>take</th>\n",
              "      <th>it</th>\n",
              "      <th>easy.</th>\n",
              "      <th>is</th>\n",
              "      <th>fun.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>sent0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sent1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sent2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows Ã— 24 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06c4b0dd-b075-4602-9934-191020afe101')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-06c4b0dd-b075-4602-9934-191020afe101 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-06c4b0dd-b075-4602-9934-191020afe101');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c6410f65-9d6f-4a77-891a-f714d496654d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c6410f65-9d6f-4a77-891a-f714d496654d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c6410f65-9d6f-4a77-891a-f714d496654d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "corpus = {}\n",
        "for i, sent in enumerate(sentence.split('\\n')):\n",
        "    corpus[f\"sent{i}\"] = dict((tok, 1) for tok in sent.split())\n",
        "\n",
        "df = pd.DataFrame.from_records(corpus).fillna(0).astype(int).T\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "every-rachel",
      "metadata": {
        "id": "every-rachel"
      },
      "source": [
        "Now we see how we managed to build feature vectors for the three sentences we originally had. Now let's do a Dot Product calculation.\n",
        "\n",
        "- *In the context of measuring similarity, the dot product is often used to quantify the **similarity** between two vectors.*\n",
        "- *The **higher** the dot product, the more **similar** the vectors are considered to be.*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "computational-tyler",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "computational-tyler",
        "outputId": "c9121871-ec41-4439-ace7-55fe481afedd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dot product of sent0 from sent1: 0 and dot product of sent0 from sent2: 3\n"
          ]
        }
      ],
      "source": [
        "df = df.T\n",
        "print(f\"Dot product of sent0 from sent1: {df.sent0.dot(df.sent1)} and dot product of sent0 from sent2: {df.sent0.dot(df.sent2)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vocational-pavilion",
      "metadata": {
        "id": "vocational-pavilion"
      },
      "source": [
        "As we see from the results, the higher the dot product to more similar the vectors are... so given that only the first and last sentence have some common words, we see that this comes back as 3, where as the two sentences who have nothing in common come bak as 0."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "arabic-realtor",
      "metadata": {
        "id": "arabic-realtor"
      },
      "source": [
        "We can improve our vocabulary now if we were to remove all other punctuation. Let's do that with regular expressions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "saving-fifty",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saving-fifty",
        "outputId": "0dd7dd9e-2f4e-49c3-d0d3-7d6a781949d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " 'Welcome',\n",
              " 'to',\n",
              " 'the',\n",
              " 'Natural',\n",
              " 'Language',\n",
              " 'Processing',\n",
              " 'lab',\n",
              " \"We'll\",\n",
              " 'learn',\n",
              " 'many',\n",
              " 'things',\n",
              " 'in',\n",
              " 'this',\n",
              " 'no',\n",
              " '1',\n",
              " 'lab',\n",
              " 'so',\n",
              " 'we',\n",
              " 'will',\n",
              " 'take',\n",
              " 'it',\n",
              " 'easy',\n",
              " 'Natural',\n",
              " 'Language',\n",
              " 'Processing',\n",
              " 'is',\n",
              " 'fun',\n",
              " '']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "tokens = re.split(r\"[-\\s.,;!?]+\", sentence)\n",
        "tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "710aa204",
      "metadata": {
        "id": "710aa204"
      },
      "source": [
        "## NLTK\n",
        "\n",
        "Although this seems to be great... you might still have issues with different characters that are not anticipated. So we usually use an existing NLP related tokeniser to do this job. Let's try the NLTK lib.\n",
        "\n",
        "NLTK also supports regular expressions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "prime-limit",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prime-limit",
        "outputId": "2562cc7f-6080-4546-a9fb-52af9482421d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Welcome',\n",
              " 'to',\n",
              " 'the',\n",
              " 'Natural',\n",
              " 'Language',\n",
              " 'Processing',\n",
              " 'lab',\n",
              " '!',\n",
              " 'We',\n",
              " \"'ll\",\n",
              " 'learn',\n",
              " 'many',\n",
              " 'things',\n",
              " 'in',\n",
              " 'this',\n",
              " 'no',\n",
              " '1',\n",
              " 'lab',\n",
              " ',',\n",
              " 'so',\n",
              " 'we',\n",
              " 'will',\n",
              " 'take',\n",
              " 'it',\n",
              " 'easy',\n",
              " '.',\n",
              " 'Natural',\n",
              " 'Language',\n",
              " 'Processing',\n",
              " 'is',\n",
              " 'fun',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "tokenizer = RegexpTokenizer(r\"\\w+|$[0-9.]+|\\S+\")\n",
        "tokenizer.tokenize(sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "handmade-prototype",
      "metadata": {
        "id": "handmade-prototype"
      },
      "source": [
        "but there are other more specialised tokenisers, such as the *Treebank Word Tokenizer*:\n",
        "\n",
        "\n",
        "- *It is specifically designed to tokenize text in a manner similar to the **Penn Treebank Tokenization conventions**.*\n",
        "- *The Penn Treebank is a **large corpus** of English text, and the tokenization conventions used in its processing have become a standard for various NLP tasks.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "rapid-dictionary",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rapid-dictionary",
        "outputId": "bdcbcac3-9fbe-4567-9682-65233e032054"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Welcome',\n",
              " 'to',\n",
              " 'the',\n",
              " 'Natural',\n",
              " 'Language',\n",
              " 'Processing',\n",
              " 'lab',\n",
              " '!',\n",
              " 'We',\n",
              " \"'ll\",\n",
              " 'learn',\n",
              " 'many',\n",
              " 'things',\n",
              " 'in',\n",
              " 'this',\n",
              " 'no',\n",
              " '1',\n",
              " 'lab',\n",
              " ',',\n",
              " 'so',\n",
              " 'we',\n",
              " 'will',\n",
              " 'take',\n",
              " 'it',\n",
              " 'easy.',\n",
              " 'Natural',\n",
              " 'Language',\n",
              " 'Processing',\n",
              " 'is',\n",
              " 'fun',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "tokenizer.tokenize(sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adjusted-graphic",
      "metadata": {
        "id": "adjusted-graphic"
      },
      "source": [
        "For now let's use the regular expression special word pattern `\\w`, so we can control what the tokeniser does."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "south-engine",
      "metadata": {
        "id": "south-engine",
        "outputId": "12ff114e-2f8a-4d06-d51e-dcbabd74b709"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Welcome', 'to', 'the', 'Natural', 'Language', 'Processing', 'lab', 'We', 'll', 'learn', 'many', 'things', 'in', 'this', 'no', '1', 'lab', 'so', 'we', 'will', 'take', 'it', 'easy', 'Natural', 'Language', 'Processing', 'is', 'fun']\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "#\\w is a special sequence in regular expressions that matches any alphanumeric character, including letters (both uppercase and lowercase) and digits.\n",
        "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
        "tokens = tokenizer.tokenize(sentence)\n",
        "print(tokens)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "loved-category",
      "metadata": {
        "id": "loved-category"
      },
      "source": [
        "At the point you could try out different other tokenisers from other libraries and see if there are any differences.\n",
        "\n",
        "We will now calculate the 2-grams:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "guilty-export",
      "metadata": {
        "id": "guilty-export",
        "outputId": "3a0e4a78-aade-4ddc-9762-70399f02e81e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('Welcome', 'to'),\n",
              " ('to', 'the'),\n",
              " ('the', 'Natural'),\n",
              " ('Natural', 'Language'),\n",
              " ('Language', 'Processing'),\n",
              " ('Processing', 'lab'),\n",
              " ('lab', 'We'),\n",
              " ('We', 'll'),\n",
              " ('ll', 'learn'),\n",
              " ('learn', 'many'),\n",
              " ('many', 'things'),\n",
              " ('things', 'in'),\n",
              " ('in', 'this'),\n",
              " ('this', 'no'),\n",
              " ('no', '1'),\n",
              " ('1', 'lab'),\n",
              " ('lab', 'so'),\n",
              " ('so', 'we'),\n",
              " ('we', 'will'),\n",
              " ('will', 'take'),\n",
              " ('take', 'it'),\n",
              " ('it', 'easy'),\n",
              " ('easy', 'Natural'),\n",
              " ('Natural', 'Language'),\n",
              " ('Language', 'Processing'),\n",
              " ('Processing', 'is'),\n",
              " ('is', 'fun')]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.util import ngrams\n",
        "\n",
        "list(ngrams(tokens, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "connected-present",
      "metadata": {
        "id": "connected-present"
      },
      "source": [
        "and 3-grams:\n",
        "\n",
        "These *$n$-grams* are a contiguous sequence of $n$ items from a given sample of text or speech. They can be used to **identify** common phrases or expressions and can be valuable in tasks like language modeling, where predicting the next word is based on the preceding one.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "imperial-retreat",
      "metadata": {
        "id": "imperial-retreat",
        "outputId": "ccc644f5-7f28-4c25-dd42-bd085b71e297"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('Welcome', 'to', 'the'),\n",
              " ('to', 'the', 'Natural'),\n",
              " ('the', 'Natural', 'Language'),\n",
              " ('Natural', 'Language', 'Processing'),\n",
              " ('Language', 'Processing', 'lab'),\n",
              " ('Processing', 'lab', 'We'),\n",
              " ('lab', 'We', 'll'),\n",
              " ('We', 'll', 'learn'),\n",
              " ('ll', 'learn', 'many'),\n",
              " ('learn', 'many', 'things'),\n",
              " ('many', 'things', 'in'),\n",
              " ('things', 'in', 'this'),\n",
              " ('in', 'this', 'no'),\n",
              " ('this', 'no', '1'),\n",
              " ('no', '1', 'lab'),\n",
              " ('1', 'lab', 'so'),\n",
              " ('lab', 'so', 'we'),\n",
              " ('so', 'we', 'will'),\n",
              " ('we', 'will', 'take'),\n",
              " ('will', 'take', 'it'),\n",
              " ('take', 'it', 'easy'),\n",
              " ('it', 'easy', 'Natural'),\n",
              " ('easy', 'Natural', 'Language'),\n",
              " ('Natural', 'Language', 'Processing'),\n",
              " ('Language', 'Processing', 'is'),\n",
              " ('Processing', 'is', 'fun')]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(ngrams(tokens, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aggregate-shooting",
      "metadata": {
        "id": "aggregate-shooting"
      },
      "source": [
        "If we want to include the n-grams as strings rather than tuples, then we need to convert them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "twenty-enhancement",
      "metadata": {
        "id": "twenty-enhancement",
        "outputId": "94a2584b-2875-4a10-e45c-ab5b2030571b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bigrams: ['Welcome to', 'to the', 'the Natural', 'Natural Language', 'Language Processing', 'Processing lab', 'lab We', 'We ll', 'll learn', 'learn many', 'many things', 'things in', 'in this', 'this no', 'no 1', '1 lab', 'lab so', 'so we', 'we will', 'will take', 'take it', 'it easy', 'easy Natural', 'Natural Language', 'Language Processing', 'Processing is', 'is fun']\n",
            "\n",
            "Trigrams: ['Welcome to the', 'to the Natural', 'the Natural Language', 'Natural Language Processing', 'Language Processing lab', 'Processing lab We', 'lab We ll', 'We ll learn', 'll learn many', 'learn many things', 'many things in', 'things in this', 'in this no', 'this no 1', 'no 1 lab', '1 lab so', 'lab so we', 'so we will', 'we will take', 'will take it', 'take it easy', 'it easy Natural', 'easy Natural Language', 'Natural Language Processing', 'Language Processing is', 'Processing is fun']\n"
          ]
        }
      ],
      "source": [
        "bigrams = [\" \".join(x) for x in list(ngrams(tokens, 2))]\n",
        "print(f\"Bigrams: {bigrams}\\n\")\n",
        "\n",
        "trigrams = [\" \".join(x) for x in list(ngrams(tokens, 3))]\n",
        "print(f\"Trigrams: {trigrams}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "seven-syracuse",
      "metadata": {
        "id": "seven-syracuse"
      },
      "source": [
        "Another important step we looked at in the lectures are the stop words. Let's try to use the nltk stop word list to remove them.\n",
        "\n",
        "These are words that are *commonly used* in a language but are typically *filtered out* during text processing because they are considered to carry little to no meaning on their own.\n",
        "\n",
        "First, let's download the list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "apparent-going",
      "metadata": {
        "id": "apparent-going",
        "outputId": "1df273c0-ee79-4814-f2d9-dde77b8f3c3b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /home/studio-lab-\n",
            "[nltk_data]     user/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "annual-disorder",
      "metadata": {
        "id": "annual-disorder"
      },
      "source": [
        "and now check it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pending-reducing",
      "metadata": {
        "id": "pending-reducing",
        "outputId": "8df3e6c6-fa3f-40ef-dc16-6e1d7335fe52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of stopwords: 179\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ],
      "source": [
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "print(f\"number of stopwords: {len(stop_words)}\")\n",
        "print(stop_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "friendly-expression",
      "metadata": {
        "id": "friendly-expression"
      },
      "source": [
        "Other libs have different stopwords. Let's see a much larger set from sklearn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "monthly-armenia",
      "metadata": {
        "id": "monthly-armenia",
        "outputId": "199bca11-3c7d-4b97-fb9b-0c1d8bdc2c74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of stopwords: 318\n",
            "frozenset({'without', 'mine', 'another', 'almost', 'further', 'thereupon', 'it', 'third', 'until', 'when', 'for', 'only', 'every', 'nevertheless', 'somehow', 'neither', 'formerly', 'find', 'if', 'all', 'get', 'mostly', 'while', 'thus', 'wherein', 'three', 'around', 'ourselves', 'should', 'except', 'have', 'seem', 'anyone', 'thick', 'take', 'con', 'again', 'fire', 'seeming', 'couldnt', 'a', 'on', 'whereafter', 'this', 'will', 'whereby', 'few', 'against', 'must', 'before', 'mill', 'etc', 'thence', 'our', 'interest', 'thru', 'within', 'done', 'herself', 'hereupon', 'yet', 'un', 'been', 'was', 'nothing', 'still', 'empty', 'anyway', 'two', 'anyhow', 'sometime', 'together', 'up', 'whenever', 'between', 'becoming', 'me', 'everywhere', 'themselves', 'namely', 'since', 'fill', 'more', 'beside', 'four', 'ie', 'us', 'wherever', 'several', 'of', 'itself', 'latterly', 'please', 'off', 'show', 'any', 'first', 'give', 'also', 'well', 'whereupon', 'part', 'might', 'down', 'nor', 'alone', 'hundred', 'due', 'twelve', 'seems', 'detail', 'some', 'move', 'by', 'you', 'became', 'behind', 'but', 'cannot', 'is', 'both', 'everyone', 'sixty', 'what', 'then', 'anywhere', 'she', 'besides', 'go', 'himself', 'thereafter', 'never', 'least', 'anything', 'meanwhile', 'ours', 'their', 'hence', 'bottom', 'with', 'thereby', 'throughout', 'although', 'toward', 'someone', 'we', 'rather', 'as', 'many', 'amount', 'afterwards', 'describe', 'side', 'however', 'most', 'latter', 'has', 'co', 'ten', 'had', 'serious', 'his', 'otherwise', 'among', 'whither', 'there', 'back', 'hereby', 'front', 'nine', 'from', 'beforehand', 'yourself', 'amoungst', 'her', 'where', 'somewhere', 'name', 'eleven', 'last', 'therefore', 'ltd', 'much', 'once', 'whole', 'own', 'de', 'along', 'do', 'ever', 'how', 'an', 'via', 'six', 'made', 'else', 'than', 'whereas', 'same', 'hers', 'and', 'whoever', 'yours', 'cry', 'five', 'eight', 'see', 'that', 'so', 'he', 'keep', 'above', 'elsewhere', 'therein', 'because', 'nobody', 'am', 'hereafter', 'onto', 'being', 'hasnt', 'myself', 'something', 'your', 'below', 'or', 'in', 'be', 'the', 'can', 'next', 'sincere', 'not', 'could', 'other', 'twenty', 'about', 'often', 'former', 'whence', 'system', 'no', 'even', 'over', 'are', 'whether', 'why', 'already', 'top', 'others', 'found', 'may', 'indeed', 'they', 'sometimes', 'its', 'inc', 'cant', 'yourselves', 'under', 'whose', 'always', 'less', 'bill', 'everything', 'would', 'noone', 'amongst', 'were', 'very', 'through', 'those', 'during', 'into', 'my', 'out', 'nowhere', 'put', 're', 'herein', 'i', 'at', 'to', 'seemed', 'thin', 'whatever', 'now', 'either', 'call', 'which', 'eg', 'full', 'forty', 'after', 'per', 'these', 'whom', 'though', 'him', 'towards', 'moreover', 'across', 'none', 'too', 'fifty', 'enough', 'each', 'who', 'perhaps', 'fifteen', 'becomes', 'one', 'upon', 'here', 'become', 'beyond', 'them', 'such'})\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as sklearn_stop_words\n",
        "\n",
        "print(f\"number of stopwords: {len(sklearn_stop_words)}\")\n",
        "print(sklearn_stop_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "exempt-deviation",
      "metadata": {
        "id": "exempt-deviation"
      },
      "source": [
        "Strangely enough, although there are more stop words in sklearn, you will find that nltk has words that are not contained in sklearn. So you might want to join the two lists.\n",
        "\n",
        "For normalising the text you could do something as simple as making sure all words are lower case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "alive-employee",
      "metadata": {
        "id": "alive-employee",
        "outputId": "9d01852c-4672-43b3-8b06-85e0dbfc019d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['welcome', 'to', 'the', 'natural', 'language', 'processing', 'lab', 'we', 'll', 'learn', 'many', 'things', 'in', 'this', 'no', '1', 'lab', 'so', 'we', 'will', 'take', 'it', 'easy', 'natural', 'language', 'processing', 'is', 'fun']\n"
          ]
        }
      ],
      "source": [
        "norm_tokens = [x.lower() for x in tokens]\n",
        "print(norm_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ongoing-inflation",
      "metadata": {
        "id": "ongoing-inflation"
      },
      "source": [
        "For stemming the words we could use nltk again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "upset-reputation",
      "metadata": {
        "id": "upset-reputation",
        "outputId": "ef21a6e6-975c-41d0-c963-40efefdccc72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['welcom', 'to', 'the', 'natur', 'languag', 'process', 'lab', 'we', 'll', 'learn', 'mani', 'thing', 'in', 'thi', 'no', '1', 'lab', 'so', 'we', 'will', 'take', 'it', 'easi', 'natur', 'languag', 'process', 'is', 'fun']\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "stem_tokens = [stemmer.stem(x) for x in norm_tokens]\n",
        "print(stem_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gothic-porter",
      "metadata": {
        "id": "gothic-porter"
      },
      "source": [
        "For lemmatising, nltk also does the trick."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "desperate-diploma",
      "metadata": {
        "id": "desperate-diploma",
        "outputId": "387feb38-bdda-4316-b6ac-6818e9bf0318"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /home/studio-lab-\n",
            "[nltk_data]     user/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /home/studio-lab-\n",
            "[nltk_data]     user/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['welcome', 'to', 'the', 'natural', 'language', 'processing', 'lab', 'we', 'll', 'learn', 'many', 'thing', 'in', 'this', 'no', '1', 'lab', 'so', 'we', 'will', 'take', 'it', 'easy', 'natural', 'language', 'processing', 'is', 'fun']\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"omw-1.4\")\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stem_tokens = [lemmatizer.lemmatize(x) for x in norm_tokens]\n",
        "print(stem_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "coordinated-relevance",
      "metadata": {
        "id": "coordinated-relevance"
      },
      "source": [
        "With this example sentence, there are no issues with the lemmatisation... but let's look at the following example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "understanding-veteran",
      "metadata": {
        "id": "understanding-veteran",
        "outputId": "0d772e42-9bdd-4984-9586-8c605d2e8c21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "better\n",
            "good\n"
          ]
        }
      ],
      "source": [
        "print(lemmatizer.lemmatize(\"better\"))\n",
        "print(lemmatizer.lemmatize(\"better\", \"a\"))  # declaring the POS as adjective"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "intimate-martin",
      "metadata": {
        "id": "intimate-martin"
      },
      "source": [
        "If we don't include the Part-of-speech (POS), nltk, using wordnet, does not work well. So let's try to fix that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "russian-merit",
      "metadata": {
        "id": "russian-merit"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import wordnet\n",
        "\n",
        "def get_wordnet_pos(word):\n",
        "    \"\"\"Map the POS tag to the first character lemmatize() accepts.\"\"\"\n",
        "\n",
        "    try:  # download nltk's POS tagger if it doesn't exist\n",
        "        nltk.data.find(\"taggers/averaged_perceptron_tagger\")\n",
        "    except LookupError:\n",
        "        nltk.download(\"averaged_perceptron_tagger\")\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()  # use ntlk's POS tagger on the word\n",
        "\n",
        "    # now we need to convert from nltk to wordnet POS notations (for compatibility reasons)\n",
        "    tag_dict = {\n",
        "        \"J\": wordnet.ADJ,\n",
        "        \"N\": wordnet.NOUN,\n",
        "        \"V\": wordnet.VERB,\n",
        "        \"R\": wordnet.ADV\n",
        "    }\n",
        "\n",
        "    return tag_dict.get(tag, wordnet.NOUN)  # return and default to noun if not found"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "imperial-comparative",
      "metadata": {
        "id": "imperial-comparative",
        "outputId": "c90379a0-69fe-4f29-96d1-c8f961eb00f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['welcome', 'to', 'the', 'natural', 'language', 'processing', 'lab', 'we', 'll', 'learn', 'many', 'thing', 'in', 'this', 'no', '1', 'lab', 'so', 'we', 'will', 'take', 'it', 'easy', 'natural', 'language', 'processing', 'be', 'fun']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "stem_tokens = [lemmatizer.lemmatize(x, pos=get_wordnet_pos(x)) for x in norm_tokens]\n",
        "print(stem_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "inside-assignment",
      "metadata": {
        "id": "inside-assignment"
      },
      "source": [
        "If we look at the words now we are getting more counts for our bag of words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "polished-simon",
      "metadata": {
        "id": "polished-simon",
        "outputId": "9a2cb671-e98a-4735-e883-23c5a9575d3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({'welcome': 1,\n",
              "         'to': 1,\n",
              "         'the': 1,\n",
              "         'natural': 2,\n",
              "         'language': 2,\n",
              "         'processing': 2,\n",
              "         'lab': 2,\n",
              "         'we': 2,\n",
              "         'll': 1,\n",
              "         'learn': 1,\n",
              "         'many': 1,\n",
              "         'thing': 1,\n",
              "         'in': 1,\n",
              "         'this': 1,\n",
              "         'no': 1,\n",
              "         '1': 1,\n",
              "         'so': 1,\n",
              "         'will': 1,\n",
              "         'take': 1,\n",
              "         'it': 1,\n",
              "         'easy': 1,\n",
              "         'be': 1,\n",
              "         'fun': 1})"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "bow = Counter(stem_tokens)\n",
        "bow"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "optional-healthcare",
      "metadata": {
        "id": "optional-healthcare"
      },
      "source": [
        "Now let's check the most frequent 6 words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "unable-champagne",
      "metadata": {
        "id": "unable-champagne",
        "outputId": "dd98e84c-5614-483c-df75-c43a86dc75a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('natural', 2),\n",
              " ('language', 2),\n",
              " ('processing', 2),\n",
              " ('lab', 2),\n",
              " ('we', 2),\n",
              " ('welcome', 1)]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bow.most_common(6)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cross-hayes",
      "metadata": {
        "id": "cross-hayes"
      },
      "source": [
        "Now let's remove the stop words and check the count again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "graduate-showcase",
      "metadata": {
        "id": "graduate-showcase",
        "outputId": "bface5c9-228a-44b0-9ca6-bf34c23a81a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({'welcome': 1,\n",
              "         'natural': 2,\n",
              "         'language': 2,\n",
              "         'processing': 2,\n",
              "         'lab': 2,\n",
              "         'learn': 1,\n",
              "         'many': 1,\n",
              "         'thing': 1,\n",
              "         '1': 1,\n",
              "         'take': 1,\n",
              "         'easy': 1,\n",
              "         'fun': 1})"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "no_stop_tokens = [x for x in stem_tokens if x not in stop_words]\n",
        "count = Counter(no_stop_tokens)\n",
        "count"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "discrete-favor",
      "metadata": {
        "id": "discrete-favor"
      },
      "source": [
        "Finally... let's make our feature vector using the frequency ratio (term count / total number of terms in the doc):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "retained-medicine",
      "metadata": {
        "id": "retained-medicine",
        "outputId": "eaae2f23-99eb-491f-b593-dbc158139578"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.125, 0.125, 0.125, 0.125, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625]\n"
          ]
        }
      ],
      "source": [
        "document_vector = []\n",
        "doc_length = len(no_stop_tokens)\n",
        "for key, value in count.most_common():\n",
        "    document_vector.append(value / doc_length)\n",
        "\n",
        "print(document_vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "forced-spell",
      "metadata": {
        "id": "forced-spell"
      },
      "source": [
        "We have explored many many options already and we will continue with more advanced feature vectors in the next lab, plus some visualisations in charts. So until then please try different experiments on your own:\n",
        "1. See if you can change the text and have more sentences with different topics (so you can compare the feature vectors later)\n",
        "2. Try to use different libraries for tokenising, PoS tagging, stemming and lemmatising.\n",
        "3. Try to use distance metrics to compare vectors, such as Euclidian distance."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}